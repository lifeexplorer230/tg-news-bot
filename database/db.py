"""–†–∞–±–æ—Ç–∞ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö SQLite"""

from __future__ import annotations

import io
import sqlite3
import threading
import time
from datetime import datetime, timedelta
from pathlib import Path

import numpy as np

from utils.logger import setup_logger
from utils.timezone import get_timezone, now_in_timezone, now_msk, now_utc, to_utc
from database.connection_pool import ConnectionPool

logger = setup_logger(__name__)


def retry_on_locked(func):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ –ë–î"""

    def wrapper(self, *args, **kwargs):
        max_retries = getattr(self, "_retry_max_attempts", 5)
        base_delay = getattr(self, "_retry_base_delay", 0.5)
        multiplier = getattr(self, "_retry_backoff_multiplier", 1.0)

        for attempt in range(max_retries):
            try:
                return func(self, *args, **kwargs)
            except sqlite3.OperationalError as e:
                if "database is locked" in str(e) and attempt < max_retries - 1:
                    delay = base_delay * (attempt + 1) * multiplier
                    logger.warning(
                        "–ë–î –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞, –ø–æ–ø—ã—Ç–∫–∞ %s/%s, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ %.2f c",
                        attempt + 1,
                        max_retries,
                        delay,
                    )
                    time.sleep(delay)
                    continue
                raise
        return None

    return wrapper


class Database:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å SQLite –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""

    def __init__(
        self,
        db_path: str,
        *,
        timeout: float = 30.0,
        busy_timeout_ms: int = 30000,
        retry_max_attempts: int = 5,
        retry_base_delay: float = 0.5,
        retry_backoff_multiplier: float = 1.0,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

        Args:
            db_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        """
        self.db_path = db_path
        self._timeout = float(timeout)
        self._busy_timeout_ms = int(busy_timeout_ms)
        self._retry_max_attempts = max(1, int(retry_max_attempts))
        self._retry_base_delay = max(0.0, float(retry_base_delay))
        self._retry_backoff_multiplier = max(0.0, float(retry_backoff_multiplier)) or 1.0
        Path(db_path).parent.mkdir(parents=True, exist_ok=True)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º connection pool –≤–º–µ—Å—Ç–æ –æ–¥–Ω–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        self._pool = ConnectionPool(
            db_path,
            max_connections=5,  # 5 —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –≤ –ø—É–ª–µ
            timeout=timeout,
            busy_timeout_ms=busy_timeout_ms
        )

        self.conn: sqlite3.Connection | None = None  # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        self._lock = threading.Lock()  # Thread safety –¥–ª—è write operations
        self._closed = False  # Track if connection was explicitly closed
        self.init_db()

    def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º
        # –í –Ω–æ–≤–æ–º –∫–æ–¥–µ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å get_connection()
        if self.conn is None:
            self.conn = self._pool._create_connection()
        return self.conn

    def get_connection(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–∑ –ø—É–ª–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –º–µ—Ç–æ–¥)"""
        return self._pool.get_connection()

    def init_db(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç"""
        conn = self.connect()
        cursor = conn.cursor()

        # –¢–∞–±–ª–∏—Ü–∞ –∫–∞–Ω–∞–ª–æ–≤
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS channels (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username TEXT UNIQUE NOT NULL,
                title TEXT,
                is_active BOOLEAN DEFAULT 1,
                added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """
        )

        # –¢–∞–±–ª–∏—Ü–∞ —Å—ã—Ä—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS raw_messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                channel_id INTEGER NOT NULL,
                message_id INTEGER NOT NULL,
                text TEXT NOT NULL,
                date TIMESTAMP NOT NULL,
                has_media BOOLEAN DEFAULT 0,
                processed BOOLEAN DEFAULT 0,
                is_duplicate BOOLEAN DEFAULT 0,
                gemini_score INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (channel_id) REFERENCES channels(id),
                UNIQUE(channel_id, message_id)
            )
        """
        )

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ –ø–æ–ª–µ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        cursor.execute("PRAGMA table_info(raw_messages)")
        columns = [col[1] for col in cursor.fetchall()]
        if "rejection_reason" not in columns:
            cursor.execute("ALTER TABLE raw_messages ADD COLUMN rejection_reason TEXT")
            logger.info("–î–æ–±–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ rejection_reason –≤ raw_messages")

        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è raw_messages
        cursor.execute(
            """
            CREATE INDEX IF NOT EXISTS idx_processed
            ON raw_messages(processed, date)
        """
        )
        cursor.execute(
            """
            CREATE INDEX IF NOT EXISTS idx_date
            ON raw_messages(date)
        """
        )

        # –¢–∞–±–ª–∏—Ü–∞ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS published (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                text TEXT NOT NULL,
                embedding BLOB,
                source_message_id INTEGER,
                source_channel_id INTEGER,
                published_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (source_message_id) REFERENCES raw_messages(id)
            )
        """
        )

        cursor.execute(
            """
            CREATE INDEX IF NOT EXISTS idx_published_date
            ON published(published_at)
        """
        )

        # –ú–∏–≥—Ä–∞—Ü–∏—è: —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –¥–æ–±–∞–≤–ª—è–µ–º UNIQUE constraint –Ω–∞ source_message_id
        # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏—é –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–≤–∞–∂–¥—ã
        self._migrate_published_unique_constraint(cursor)

        # –¢–∞–±–ª–∏—Ü–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS config (
                key TEXT PRIMARY KEY,
                value TEXT
            )
        """
        )

        conn.commit()
        logger.info(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {self.db_path}")

    def _migrate_published_unique_constraint(self, cursor: sqlite3.Cursor):
        """
        –ú–∏–≥—Ä–∞—Ü–∏—è: –¥–æ–±–∞–≤–∏—Ç—å UNIQUE constraint –Ω–∞ (source_message_id, source_channel_id)

        –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏—é –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–≤–∞–∂–¥—ã.
        –ú–∏–≥—Ä–∞—Ü–∏—è –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–∞ - –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ.
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ –∏–Ω–¥–µ–∫—Å
        cursor.execute(
            "SELECT name FROM sqlite_master WHERE type='index' AND name='idx_published_source_unique'"
        )
        if cursor.fetchone():
            # –ò–Ω–¥–µ–∫—Å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –º–∏–≥—Ä–∞—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞
            return

        logger.info("üîÑ –ó–∞–ø—É—Å–∫ –º–∏–≥—Ä–∞—Ü–∏–∏: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ UNIQUE constraint –Ω–∞ published")

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º
        cursor.execute("""
            SELECT COUNT(*) FROM published
            WHERE id NOT IN (
                SELECT MAX(id) FROM published
                WHERE source_message_id IS NOT NULL
                GROUP BY source_message_id, source_channel_id
            )
            AND source_message_id IS NOT NULL
        """)
        duplicate_count = cursor.fetchone()[0]

        if duplicate_count > 0:
            logger.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {duplicate_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ published, —É–¥–∞–ª—è–µ–º...")

            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã
            cursor.execute("""
                DELETE FROM published
                WHERE id NOT IN (
                    SELECT MAX(id) FROM published
                    WHERE source_message_id IS NOT NULL
                    GROUP BY source_message_id, source_channel_id
                )
                AND source_message_id IS NOT NULL
            """)
            logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {duplicate_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")

        # –°–æ–∑–¥–∞—ë–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å
        cursor.execute("""
            CREATE UNIQUE INDEX IF NOT EXISTS idx_published_source_unique
            ON published(source_message_id, source_channel_id)
            WHERE source_message_id IS NOT NULL
        """)
        logger.info("‚úÖ –°–æ–∑–¥–∞–Ω UNIQUE –∏–Ω–¥–µ–∫—Å idx_published_source_unique")

    # ====== –†–ê–ë–û–¢–ê –° –ö–ê–ù–ê–õ–ê–ú–ò ======

    @retry_on_locked
    def add_channel(self, username: str, title: str = "") -> int:
        """
        –î–æ–±–∞–≤–∏—Ç—å –∫–∞–Ω–∞–ª –≤ –±–∞–∑—É

        Args:
            username: Username –∫–∞–Ω–∞–ª–∞ (—Å @ –∏–ª–∏ –±–µ–∑)
            title: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞

        Returns:
            ID –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞
        """
        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            username = username.lstrip("@")
            cursor = self.conn.cursor()

            try:
                cursor.execute(
                    "INSERT INTO channels (username, title) VALUES (?, ?)", (username, title)
                )
                self.conn.commit()
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –∫–∞–Ω–∞–ª: @{username}")
                return cursor.lastrowid
            except sqlite3.IntegrityError:
                # –ö–∞–Ω–∞–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                cursor.execute("SELECT id FROM channels WHERE username = ?", (username,))
                return cursor.fetchone()[0]

    def get_channel_id(self, username: str) -> int | None:
        """–ü–æ–ª—É—á–∏—Ç—å ID –∫–∞–Ω–∞–ª–∞ –ø–æ username"""
        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            username = username.lstrip("@")
            cursor = self.conn.cursor()
            cursor.execute("SELECT id FROM channels WHERE username = ?", (username,))
            row = cursor.fetchone()
            return row[0] if row else None

    def get_active_channels(self) -> list[dict]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤"""
        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            cursor = self.conn.cursor()
            cursor.execute("SELECT * FROM channels WHERE is_active = 1")
            return [dict(row) for row in cursor.fetchall()]

    # ====== –†–ê–ë–û–¢–ê –° –°–û–û–ë–©–ï–ù–ò–Ø–ú–ò ======

    @retry_on_locked
    def save_message(
        self, channel_id: int, message_id: int, text: str, date: datetime, has_media: bool = False
    ) -> int | None:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ –∫–∞–Ω–∞–ª–∞

        Args:
            channel_id: ID –∫–∞–Ω–∞–ª–∞
            message_id: ID —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram
            text: –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            date: –î–∞—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
            has_media: –ï—Å—Ç—å –ª–∏ –º–µ–¥–∏–∞

        Returns:
            ID –∑–∞–ø–∏—Å–∏ –∏–ª–∏ None –µ—Å–ª–∏ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        """
        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            cursor = self.conn.cursor()

            try:
                cursor.execute(
                    """
                    INSERT INTO raw_messages
                    (channel_id, message_id, text, date, has_media)
                    VALUES (?, ?, ?, ?, ?)
                """,
                    (channel_id, message_id, text, date, has_media),
                )
                self.conn.commit()
                return cursor.lastrowid
            except sqlite3.IntegrityError:
                # –°–æ–æ–±—â–µ–Ω–∏–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                return None

    def get_unprocessed_messages(self, hours: int = 24) -> list[dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤

        Args:
            hours: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            cursor = self.conn.cursor()
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º UTC –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, —Ç.–∫. message.date —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ UTC
            cutoff_time = now_utc() - timedelta(hours=hours)

            cursor.execute(
                """
                SELECT m.*, c.username as channel_username
                FROM raw_messages m
                JOIN channels c ON m.channel_id = c.id
                WHERE m.processed = 0
                  AND m.date > ?
                ORDER BY m.date DESC
            """,
                (cutoff_time,),
            )

            return [dict(row) for row in cursor.fetchall()]

    @retry_on_locked
    def mark_as_processed(
        self,
        message_id: int,
        is_duplicate: bool = False,
        gemini_score: int | None = None,
        rejection_reason: str | None = None,
    ):
        """
        –ü–æ–º–µ—Ç–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ

        Args:
            message_id: ID —Å–æ–æ–±—â–µ–Ω–∏—è
            is_duplicate: –Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–º
            gemini_score: –û—Ü–µ–Ω–∫–∞ Gemini (–¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–π)
            rejection_reason: –ü—Ä–∏—á–∏–Ω–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ –Ω–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ)
        """
        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            cursor = self.conn.cursor()
            cursor.execute(
                """
                UPDATE raw_messages
                SET processed = 1,
                    is_duplicate = ?,
                    gemini_score = ?,
                    rejection_reason = ?
                WHERE id = ?
            """,
                (is_duplicate, gemini_score, rejection_reason, message_id),
            )
            self.conn.commit()

    @retry_on_locked
    def mark_as_processed_batch(self, updates: list[dict]):
        """
        –ë–∞—Ç—á-–ø–æ–º–µ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∑–∞ –æ–¥–Ω—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é (Sprint 6.1)

        –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –≤–º–µ—Å—Ç–æ N –∫–æ–º–º–∏—Ç–æ–≤ –¥–µ–ª–∞–µ–º 1 –∫–æ–º–º–∏—Ç –Ω–∞ –≤–µ—Å—å –±–∞—Ç—á.
        –†–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∏–∑–±—ã—Ç–æ—á–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π SQLite.

        Args:
            updates: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ–ª—è–º–∏:
                - message_id: int (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
                - is_duplicate: bool (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é False)
                - gemini_score: int | None (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é None)
                - rejection_reason: str | None (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é None)

        Example:
            updates = [
                {'message_id': 1, 'rejection_reason': 'spam'},
                {'message_id': 2, 'is_duplicate': True},
                {'message_id': 3, 'gemini_score': 8},
            ]
            db.mark_as_processed_batch(updates)
        """
        if not updates:
            return

        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            cursor = self.conn.cursor()

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è executemany
            # –ü–æ—Ä—è–¥–æ–∫: (is_duplicate, gemini_score, rejection_reason, message_id)
            batch_data = [
                (
                    update.get('is_duplicate', False),
                    update.get('gemini_score'),
                    update.get('rejection_reason'),
                    update['message_id']  # message_id –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
                )
                for update in updates
            ]

            cursor.executemany(
                """
                UPDATE raw_messages
                SET processed = 1,
                    is_duplicate = ?,
                    gemini_score = ?,
                    rejection_reason = ?
                WHERE id = ?
            """,
                batch_data
            )

            # –û–î–ò–ù commit –Ω–∞ –≤–µ—Å—å –±–∞—Ç—á!
            self.conn.commit()
            logger.debug(f"Batch processed {len(updates)} messages")

    # ====== –†–ê–ë–û–¢–ê –° –û–ü–£–ë–õ–ò–ö–û–í–ê–ù–ù–´–ú–ò –ü–û–°–¢–ê–ú–ò ======

    @retry_on_locked
    def save_published(
        self, text: str, embedding: np.ndarray, source_message_id: int, source_channel_id: int
    ) -> int:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç INSERT OR IGNORE –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        (–∑–∞—â–∏—Ç–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ë–î —á–µ—Ä–µ–∑ UNIQUE –∏–Ω–¥–µ–∫—Å –Ω–∞ source_message_id, source_channel_id)

        Args:
            text: –¢–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
            embedding: Embedding –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            source_message_id: ID –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            source_channel_id: ID –∫–∞–Ω–∞–ª–∞-–∏—Å—Ç–æ—á–Ω–∏–∫–∞

        Returns:
            ID –∑–∞–ø–∏—Å–∏ –∏–ª–∏ -1 –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (–¥—É–±–ª–∏–∫–∞—Ç)
        """
        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            cursor = self.conn.cursor()
            # –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º embedding –≤ bytes —á–µ—Ä–µ–∑ numpy (–±–µ–∑–æ–ø–∞—Å–Ω–æ, –±–µ–∑ pickle)
            buffer = io.BytesIO()
            np.save(buffer, embedding, allow_pickle=False)
            embedding_bytes = buffer.getvalue()

            cursor.execute(
                """
                INSERT OR IGNORE INTO published
                (text, embedding, source_message_id, source_channel_id)
                VALUES (?, ?, ?, ?)
            """,
                (text, embedding_bytes, source_message_id, source_channel_id),
            )
            self.conn.commit()

            if cursor.rowcount == 0:
                logger.warning(
                    f"‚ö†Ô∏è –î—É–±–ª–∏–∫–∞—Ç –ø—Ä–æ–ø—É—â–µ–Ω –≤ save_published: "
                    f"source_message_id={source_message_id}, source_channel_id={source_channel_id}"
                )
                return -1
            return cursor.lastrowid

    def get_published_embeddings(self, days: int = 60) -> list[tuple[int, np.ndarray]]:
        """
        –ü–æ–ª—É—á–∏—Ç—å embeddings –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π

        Args:
            days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥

        Returns:
            –°–ø–∏—Å–æ–∫ (id, embedding)
        """
        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            cursor = self.conn.cursor()
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º UTC, —Ç.–∫. CURRENT_TIMESTAMP –≤ SQLite = UTC
            cutoff_time = now_utc() - timedelta(days=days)

            cursor.execute(
                """
                SELECT id, embedding FROM published
                WHERE published_at > ? AND embedding IS NOT NULL
            """,
                (cutoff_time,),
            )

            results = []
            for row in cursor.fetchall():
                # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º —á–µ—Ä–µ–∑ numpy (–±–µ–∑–æ–ø–∞—Å–Ω–æ, –±–µ–∑ pickle)
                buffer = io.BytesIO(row[1])
                embedding = np.load(buffer, allow_pickle=False)
                results.append((row[0], embedding))

            return results

    def check_duplicate(self, embedding: np.ndarray, threshold: float = 0.85) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–º –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω–æ–≥–æ

        Args:
            embedding: Embedding —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.0 - 1.0)

        Returns:
            True –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç
        """
        # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –≤–Ω—É—Ç—Ä–∏ get_published_embeddings
        published_embeddings = self.get_published_embeddings(days=60)

        if not published_embeddings:
            return False

        embedding_norm = np.linalg.norm(embedding)
        if embedding_norm == 0:
            logger.warning("–ü–æ–ª—É—á–µ–Ω embedding —Å –Ω—É–ª–µ–≤–æ–π –Ω–æ—Ä–º–æ–π –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
            return False

        for post_id, published_embedding in published_embeddings:
            published_norm = np.linalg.norm(published_embedding)
            if published_norm == 0:
                logger.debug(
                    f"–ü—Ä–æ–ø—É—â–µ–Ω –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç {post_id} –∏–∑-–∑–∞ –Ω—É–ª–µ–≤–æ–π –Ω–æ—Ä–º—ã embedding"
                )
                continue

            similarity = np.dot(embedding, published_embedding) / (embedding_norm * published_norm)

            if similarity >= threshold:
                logger.debug(f"–ù–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: post_id={post_id}, similarity={similarity:.3f}")
                return True

        return False

    # ====== –û–ß–ò–°–¢–ö–ê ======

    @retry_on_locked
    def cleanup_old_data(self, raw_days: int = 14, published_days: int = 60):
        """
        –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ

        Args:
            raw_days: –£–¥–∞–ª–∏—Ç—å raw_messages —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
            published_days: –£–¥–∞–ª–∏—Ç—å published —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π
        """
        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            cursor = self.conn.cursor()

            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –∏—Å–ø–æ–ª—å–∑—É–µ–º UTC –¥–ª—è –æ–±–µ–∏—Ö —Ç–∞–±–ª–∏—Ü (–¥–∞—Ç—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ UTC)
            raw_cutoff = now_utc() - timedelta(days=raw_days)
            published_cutoff = now_utc() - timedelta(days=published_days)

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å—ã—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            cursor.execute("DELETE FROM raw_messages WHERE date < ?", (raw_cutoff,))
            raw_deleted = cursor.rowcount

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Å—Ç—ã
            cursor.execute("DELETE FROM published WHERE published_at < ?", (published_cutoff,))
            published_deleted = cursor.rowcount

            # –ö–æ–º–º–∏—Ç–∏–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –ø–µ—Ä–µ–¥ VACUUM
            self.conn.commit()

            # VACUUM –¥–ª—è —Å–∂–∞—Ç–∏—è –ë–î (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–Ω–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏)
            cursor.execute("VACUUM")
            logger.info(
                f"–û—á–∏—Å—Ç–∫–∞ –ë–î: —É–¥–∞–ª–µ–Ω–æ {raw_deleted} —Å—ã—Ä—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π, "
                f"{published_deleted} –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤"
            )

            return {"raw": raw_deleted, "published": published_deleted}

    def get_stats(self) -> dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –±–∞–∑–µ"""
        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            cursor = self.conn.cursor()

            stats = {}

            cursor.execute("SELECT COUNT(*) FROM channels WHERE is_active = 1")
            stats["active_channels"] = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(*) FROM raw_messages WHERE processed = 0")
            stats["unprocessed_messages"] = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(*) FROM raw_messages")
            stats["total_messages"] = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(*) FROM published")
            stats["total_published"] = cursor.fetchone()[0]

            return stats

    def get_today_stats(self, timezone_name: str | None = None) -> dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ —Å–µ–≥–æ–¥–Ω—è

        Args:
            timezone_name: –ò–º—è timezone (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'Europe/Moscow').
                          –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è UTC.

        Returns:
            dict —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        with self._lock:  # Sprint 6.2: Thread-safe –¥–æ—Å—Ç—É–ø
            cursor = self.conn.cursor()
            stats = {}

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã "—Å–µ–≥–æ–¥–Ω—è" –≤ –Ω—É–∂–Ω–æ–π timezone
            if timezone_name:
                tz = get_timezone(timezone_name)
                now = now_in_timezone(tz)
                # –ù–∞—á–∞–ª–æ –¥–Ω—è –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π timezone
                start_of_day = now.replace(hour=0, minute=0, second=0, microsecond=0)
                # –ö–æ–Ω–µ—Ü –¥–Ω—è –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π timezone
                end_of_day = start_of_day + timedelta(days=1)
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ UTC –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –ë–î
                start_utc = to_utc(start_of_day)
                end_utc = to_utc(end_of_day)
            else:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º UTC
                from datetime import UTC

                now_utc = datetime.now(UTC)
                start_utc = now_utc.replace(hour=0, minute=0, second=0, microsecond=0)
                end_utc = start_utc + timedelta(days=1)

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è SQL (SQLite —Ö—Ä–∞–Ω–∏—Ç timestamps –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ —á–∏—Å–ª–∞)
            start_str = start_utc.strftime("%Y-%m-%d %H:%M:%S")
            end_str = end_utc.strftime("%Y-%m-%d %H:%M:%S")

            # –°–æ–æ–±—â–µ–Ω–∏—è, —Å–æ–±—Ä–∞–Ω–Ω—ã–µ —Å–µ–≥–æ–¥–Ω—è
            cursor.execute(
                """
                SELECT COUNT(*) FROM raw_messages
                WHERE date >= ? AND date < ?
            """,
                (start_str, end_str),
            )
            stats["messages_today"] = cursor.fetchone()[0]

            # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å–µ–≥–æ–¥–Ω—è (created_at - –∫–æ–≥–¥–∞ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ë–î, –¥–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏)
            cursor.execute(
                """
                SELECT COUNT(*) FROM raw_messages
                WHERE created_at >= ? AND created_at < ? AND processed = 1
            """,
                (start_str, end_str),
            )
            stats["processed_today"] = cursor.fetchone()[0]

            # –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ
            cursor.execute(
                """
                SELECT COUNT(*) FROM raw_messages
                WHERE processed = 0
            """
            )
            stats["unprocessed"] = cursor.fetchone()[0]

            # –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ —Å–µ–≥–æ–¥–Ω—è
            cursor.execute(
                """
                SELECT COUNT(*) FROM published
                WHERE published_at >= ? AND published_at < ?
            """,
                (start_str, end_str),
            )
            stats["published_today"] = cursor.fetchone()[0]

            # –ê–∫—Ç–∏–≤–Ω—ã–µ –∫–∞–Ω–∞–ª—ã
            cursor.execute("SELECT COUNT(*) FROM channels WHERE is_active = 1")
            stats["active_channels"] = cursor.fetchone()[0]

            # –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π
            cursor.execute("SELECT COUNT(*) FROM raw_messages")
            stats["total_messages"] = cursor.fetchone()[0]

            # –í—Å–µ–≥–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö
            cursor.execute("SELECT COUNT(*) FROM published")
            stats["total_published"] = cursor.fetchone()[0]

            return stats

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î (idempotent, thread-safe)"""
        with self._lock:
            if self._closed:
                return  # Already closed
            if self.conn:
                try:
                    self.conn.close()
                    logger.info("–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∑–∞–∫—Ä—ã—Ç–æ")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")
                finally:
                    self.conn = None
                    self._closed = True

    def __enter__(self):
        """Context manager support"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager cleanup"""
        self.close()
        return False

    def __del__(self):
        """Cleanup on garbage collection"""
        try:
            self.close()
        except Exception:
            pass  # Suppress errors during cleanup
