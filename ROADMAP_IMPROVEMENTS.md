# üöÄ –î–û–†–û–ñ–ù–ê–Ø –ö–ê–†–¢–ê –£–õ–£–ß–®–ï–ù–ò–ô TG NEWS BOT

> **–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 2025-10-27
> **–í–µ—Ä—Å–∏—è:** 1.0
> **–ê–≤—Ç–æ—Ä:** Claude Code (Opus 4.1)

## üìä –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê –ü–†–û–ï–ö–¢–ê

| –ú–µ—Ç—Ä–∏–∫–∞ | –û—Ü–µ–Ω–∫–∞ | –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π |
|---------|--------|-------------|
| **Security** | ‚ö†Ô∏è 6/10 | –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å exposed API keys |
| **Architecture** | ‚úÖ 8/10 | –ß–∏—Å—Ç–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –µ—Å—Ç—å –∞–Ω—Ç–∏–ø–∞—Ç—Ç–µ—Ä–Ω—ã |
| **Code Quality** | ‚úÖ 7/10 | –•–æ—Ä–æ—à–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, –Ω—É–∂–µ–Ω —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –±–æ–ª—å—à–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π |
| **Performance** | ‚úÖ 9/10 | –û—Ç–ª–∏—á–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (caching, batching) |
| **Error Handling** | ‚úÖ 8/10 | –•–æ—Ä–æ—à–æ, –Ω–æ –Ω—É–∂–µ–Ω circuit breaker |
| **Testing** | ‚úÖ 7/10 | –•–æ—Ä–æ—à–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ, –Ω—É–∂–Ω—ã security tests |
| **Maintainability** | ‚úÖ 8/10 | –ß–∏—Å—Ç—ã–π –∫–æ–¥, —Ö–æ—Ä–æ—à–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è |

**–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞:** 7.6/10

---

## üö® –§–ê–ó–ê 0: –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø (–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ!)

### üî¥ CRITICAL-1: –£—Ç–µ—á–∫–∞ API –∫–ª—é—á–µ–π [SECURITY]

**–ü—Ä–æ–±–ª–µ–º–∞:** –í .env —Ñ–∞–π–ª–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è —Ä–µ–∞–ª—å–Ω—ã–µ credentials:
- Telegram API (ID, Hash, Phone)
- Gemini API key
- Perplexity API key

**–î–µ–π—Å—Ç–≤–∏—è:**

```bash
# 1. –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –æ—Ç–æ–∑–≤–∞—Ç—å –≤—Å–µ —Å–∫–æ–º–ø—Ä–æ–º–µ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª—é—á–∏:
- [ ] –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å Gemini API key: https://makersuite.google.com/app/apikey
- [ ] –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å Perplexity API key: https://www.perplexity.ai/settings/api
- [ ] –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å Telegram API credentials (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ): https://my.telegram.org/apps

# 2. –£–¥–∞–ª–∏—Ç—å .env –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ git:
git filter-branch --force --index-filter \
  "git rm --cached --ignore-unmatch .env" \
  --prune-empty --tag-name-filter cat -- --all

git push origin --force --all
git push origin --force --tags

# 3. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å secrets management:
- –î–ª—è production: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å systemd EnvironmentFile
- –î–ª—è development: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å direnv —Å .envrc.local (–≤ .gitignore)

# 4. –°–æ–∑–¥–∞—Ç—å .env.example —Å –∑–∞–ø–æ–ª–Ω–∏—Ç–µ–ª—è–º–∏:
cp .env .env.example
sed -i 's/=.*/=YOUR_VALUE_HERE/g' .env.example

# 5. –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –≤ main.py:
```

```python
# utils/security.py
def check_for_exposed_secrets(config: Config):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∫–ª—é—á–µ–π –≤ production"""
    dangerous_patterns = [
        "AIzaSy",  # Google API key prefix
        "pplx-",   # Perplexity API key prefix
        "20662102",  # Known leaked Telegram API ID
    ]

    for pattern in dangerous_patterns:
        if pattern in str(config.config):
            logger.critical(f"POTENTIAL SECRET EXPOSURE: {pattern[:8]}...")
            raise SecurityError("Exposed secrets detected! Check your .env file")
```

**–°—Ä–æ–∫:** –ù–ï–ú–ï–î–õ–ï–ù–ù–û (–¥–æ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π)

---

## üìÖ –§–ê–ó–ê 1: –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–¨ (–ù–µ–¥–µ–ª—è 1)

### 1.1 Input Sanitization [HIGH]
**–§–∞–π–ª:** `/root/tg-news-bot/services/telegram_listener.py`

```python
# utils/sanitization.py
import re
import unicodedata
from typing import Optional

def sanitize_telegram_text(text: Optional[str], max_length: int = 100000) -> str:
    """Sanitize text from Telegram messages"""
    if not text:
        return ""

    # Remove null bytes
    text = text.replace('\x00', '')

    # Remove control characters (except newlines/tabs)
    text = re.sub(r'[\x00-\x08\x0B-\x0C\x0E-\x1F\x7F]', '', text)

    # Normalize Unicode to prevent homograph attacks
    text = unicodedata.normalize('NFKC', text)

    # Limit length
    if len(text) > max_length:
        text = text[:max_length]

    return text.strip()

# –í telegram_listener.py:
from utils.sanitization import sanitize_telegram_text

async def handle_new_message(self, event):
    message = event.message
    if not message.text:
        return

    text = sanitize_telegram_text(message.text, self.MAX_MESSAGE_SIZE)
```

### 1.2 –£–ª—É—á—à–µ–Ω–Ω—ã–π Rate Limiting [HIGH]
**–§–∞–π–ª:** `/root/tg-news-bot/services/news_processor.py`

```python
# utils/advanced_rate_limiter.py
class MultiLevelRateLimiter:
    """Multi-level rate limiter –¥–ª—è Telegram API"""

    def __init__(self):
        # Per-chat limiter: 20 messages/minute
        self.per_chat_limiters: dict[int, RateLimiter] = {}
        # Global limiter: 30 requests/second
        self.global_limiter = RateLimiter(max_requests=30, per_seconds=1)
        # Burst limiter: 100 requests/10 seconds
        self.burst_limiter = RateLimiter(max_requests=100, per_seconds=10)

    async def acquire(self, chat_id: Optional[int] = None):
        # Global rate limit
        await self.global_limiter.acquire()
        await self.burst_limiter.acquire()

        # Per-chat rate limit
        if chat_id:
            if chat_id not in self.per_chat_limiters:
                self.per_chat_limiters[chat_id] = RateLimiter(
                    max_requests=20, per_seconds=60
                )
            await self.per_chat_limiters[chat_id].acquire()
```

### 1.3 Security Tests [MEDIUM]

```python
# tests/test_security.py
import pytest
from database.db import Database
from services.telegram_listener import TelegramListener
from utils.sanitization import sanitize_telegram_text

class TestSecurity:
    def test_sql_injection_protection(self):
        """Test SQL injection attempts are safely handled"""
        db = Database(":memory:")
        malicious_inputs = [
            "'; DROP TABLE channels; --",
            "' OR '1'='1",
            "'; DELETE FROM raw_messages; --",
            "\\x00\\x01\\x02",
            "' UNION SELECT * FROM channels --",
        ]

        for malicious in malicious_inputs:
            # Should not raise exception
            channel_id = db.add_channel(malicious, "test_username")
            assert channel_id is not None

            # Verify tables still exist
            channels = db.get_active_channels()
            assert isinstance(channels, list)

    def test_input_sanitization(self):
        """Test dangerous characters are removed"""
        dangerous_inputs = [
            ("test\x00\x01\x02malicious", "testmalicious"),
            ("–Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç", "–Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç"),
            ("test\x1b[31mred\x1b[0m", "test[31mred[0m"),
            ("a" * 200000, "a" * 100000),  # Length limit
        ]

        for input_text, expected in dangerous_inputs:
            result = sanitize_telegram_text(input_text)
            assert result == expected

    def test_no_exposed_secrets_in_logs(self):
        """Ensure secrets are not logged"""
        # Mock logger and check no API keys appear
        pass
```

---

## üìÖ –§–ê–ó–ê 2: –ê–†–•–ò–¢–ï–ö–¢–£–†–ê (–ù–µ–¥–µ–ª–∏ 2-3)

### 2.1 Circuit Breaker –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ [HIGH]

```python
# utils/circuit_breaker.py
import time
from enum import Enum
from typing import Optional

class CircuitState(Enum):
    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"

class CircuitBreaker:
    """Circuit breaker –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –∫–∞—Å–∫–∞–¥–Ω—ã—Ö —Å–±–æ–µ–≤"""

    def __init__(
        self,
        failure_threshold: int = 5,
        recovery_timeout: int = 60,
        expected_exception: type = Exception
    ):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.expected_exception = expected_exception
        self.failure_count = 0
        self.last_failure_time: Optional[float] = None
        self.state = CircuitState.CLOSED

    def call(self, func, *args, **kwargs):
        """Execute function with circuit breaker protection"""
        if self.state == CircuitState.OPEN:
            if self._should_attempt_reset():
                self.state = CircuitState.HALF_OPEN
            else:
                raise RuntimeError(f"Circuit breaker is OPEN")

        try:
            result = func(*args, **kwargs)
            self._on_success()
            return result
        except self.expected_exception as e:
            self._on_failure()
            raise

    def _should_attempt_reset(self) -> bool:
        return (
            self.last_failure_time and
            time.time() - self.last_failure_time >= self.recovery_timeout
        )

    def _on_success(self):
        self.failure_count = 0
        self.state = CircuitState.CLOSED

    def _on_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()
        if self.failure_count >= self.failure_threshold:
            self.state = CircuitState.OPEN
```

### 2.2 –£–±—Ä–∞—Ç—å Service Locator –∞–Ω—Ç–∏–ø–∞—Ç—Ç–µ—Ä–Ω [MEDIUM]

```python
# –í–º–µ—Å—Ç–æ:
config = config or get_container().config  # ‚ùå Service Locator

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å explicit dependency injection:
def run_processor(config: Config):  # ‚úÖ Explicit
    processor = NewsProcessor(config)
    ...

# –í main.py:
if __name__ == "__main__":
    config = load_config()  # Load once

    if mode == "processor":
        run_processor(config)  # Pass explicitly
```

### 2.3 Async Queue –≤–º–µ—Å—Ç–æ time.sleep [MEDIUM]

```python
# database/async_db.py
import asyncio
from typing import Optional

class AsyncDatabase:
    """Async wrapper –¥–ª—è Database —Å queue-based retry"""

    def __init__(self, db_path: str):
        self.db = Database(db_path)
        self._write_queue = asyncio.Queue()
        self._read_semaphore = asyncio.Semaphore(10)  # Max 10 concurrent reads

    async def execute_with_retry(self, func, *args, **kwargs):
        """Execute database operation with async retry"""
        max_retries = 5
        for attempt in range(max_retries):
            try:
                # Use asyncio.to_thread for non-blocking
                return await asyncio.to_thread(func, *args, **kwargs)
            except sqlite3.OperationalError as e:
                if "database is locked" in str(e):
                    # Async sleep instead of blocking
                    await asyncio.sleep(0.1 * (2 ** attempt))
                else:
                    raise
        raise RuntimeError(f"Database locked after {max_retries} retries")
```

### 2.4 –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ [LOW]

```python
# config/config_manager.py
from typing import Any, Dict
import threading

class ImmutableConfig:
    """Immutable configuration wrapper"""

    def __init__(self, data: Dict[str, Any]):
        self._data = self._deep_freeze(data)

    def _deep_freeze(self, obj):
        """Recursively make config immutable"""
        if isinstance(obj, dict):
            return MappingProxyType({
                k: self._deep_freeze(v) for k, v in obj.items()
            })
        elif isinstance(obj, list):
            return tuple(self._deep_freeze(item) for item in obj)
        return obj

    def get(self, key: str, default=None):
        """Get config value by dot notation"""
        # Implementation...
        pass

    def copy_with_overrides(self, overrides: Dict[str, Any]):
        """Create new config with overrides (immutable)"""
        merged = deep_merge(self._data, overrides)
        return ImmutableConfig(merged)
```

---

## üìÖ –§–ê–ó–ê 3: –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –ò –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–ï (–ù–µ–¥–µ–ª–∏ 4-5)

### 3.1 Connection Pooling –¥–ª—è Database [HIGH]

```python
# database/connection_pool.py
import sqlite3
from contextlib import contextmanager
from queue import Queue

class DatabasePool:
    """Connection pool –¥–ª—è SQLite"""

    def __init__(self, db_path: str, pool_size: int = 5):
        self.db_path = db_path
        self.pool = Queue(maxsize=pool_size)

        # Initialize connections
        for _ in range(pool_size):
            conn = self._create_connection()
            self.pool.put(conn)

    def _create_connection(self) -> sqlite3.Connection:
        conn = sqlite3.connect(
            self.db_path,
            timeout=30.0,
            isolation_level=None,  # Autocommit
            check_same_thread=False
        )
        conn.execute("PRAGMA journal_mode=WAL")
        conn.execute("PRAGMA busy_timeout=30000")
        return conn

    @contextmanager
    def get_connection(self):
        conn = self.pool.get()
        try:
            yield conn
        finally:
            self.pool.put(conn)
```

### 3.2 –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è Gemini –æ—Ç–≤–µ—Ç–æ–≤ [MEDIUM]

```python
# services/gemini_cache.py
import hashlib
import json
from datetime import datetime, timedelta
from typing import Optional

class GeminiCache:
    """LRU cache –¥–ª—è Gemini API responses"""

    def __init__(self, ttl_hours: int = 24, max_size: int = 1000):
        self.ttl = timedelta(hours=ttl_hours)
        self.max_size = max_size
        self.cache: dict[str, tuple[Any, datetime]] = {}

    def _get_key(self, messages: list, params: dict) -> str:
        """Generate cache key from request"""
        content = json.dumps({"messages": messages, "params": params}, sort_keys=True)
        return hashlib.sha256(content.encode()).hexdigest()

    def get(self, messages: list, params: dict) -> Optional[Any]:
        """Get cached response if exists and not expired"""
        key = self._get_key(messages, params)

        if key in self.cache:
            result, timestamp = self.cache[key]
            if datetime.now() - timestamp < self.ttl:
                return result
            else:
                del self.cache[key]

        return None

    def set(self, messages: list, params: dict, result: Any):
        """Cache the result"""
        if len(self.cache) >= self.max_size:
            # Remove oldest entry (simple LRU)
            oldest_key = min(self.cache, key=lambda k: self.cache[k][1])
            del self.cache[oldest_key]

        key = self._get_key(messages, params)
        self.cache[key] = (result, datetime.now())
```

### 3.3 –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π [MEDIUM]

```python
# services/batch_processor.py
import asyncio
from typing import List, Dict

class BatchMessageProcessor:
    """Batch processing –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ throughput"""

    def __init__(self, batch_size: int = 100, flush_interval: float = 5.0):
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.pending_messages: List[Dict] = []
        self._lock = asyncio.Lock()
        self._flush_task = None

    async def add_message(self, message: Dict):
        """Add message to batch"""
        async with self._lock:
            self.pending_messages.append(message)

            if len(self.pending_messages) >= self.batch_size:
                await self._flush()
            elif not self._flush_task:
                # Schedule flush after interval
                self._flush_task = asyncio.create_task(
                    self._delayed_flush()
                )

    async def _delayed_flush(self):
        """Flush after timeout"""
        await asyncio.sleep(self.flush_interval)
        async with self._lock:
            await self._flush()
            self._flush_task = None

    async def _flush(self):
        """Process batch"""
        if not self.pending_messages:
            return

        batch = self.pending_messages
        self.pending_messages = []

        # Process batch
        await self._process_batch(batch)
```

---

## üìÖ –§–ê–ó–ê 4: –ú–û–ù–ò–¢–û–†–ò–ù–ì –ò OBSERVABILITY (–ù–µ–¥–µ–ª—è 6)

### 4.1 –°–∏—Å—Ç–µ–º–∞ –∞–ª–µ—Ä—Ç–æ–≤ [HIGH]

```python
# monitoring/alerts.py
import asyncio
from enum import Enum
from typing import Optional

class AlertSeverity(Enum):
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

class AlertingService:
    """Centralized alerting system"""

    def __init__(self, config: Config):
        self.config = config
        self.telegram_bot = self._init_telegram_alerting()
        self.rate_limiter = RateLimiter(max_requests=10, per_seconds=60)

    async def alert(
        self,
        message: str,
        severity: AlertSeverity = AlertSeverity.WARNING,
        context: Optional[dict] = None
    ):
        """Send alert via configured channels"""

        # Rate limit to prevent spam
        await self.rate_limiter.acquire()

        # Format message
        formatted = self._format_alert(message, severity, context)

        # Send via multiple channels
        tasks = []

        if self.config.get("monitoring.telegram_enabled"):
            tasks.append(self._send_telegram(formatted, severity))

        if self.config.get("monitoring.log_alerts"):
            tasks.append(self._log_alert(formatted, severity))

        if severity in [AlertSeverity.ERROR, AlertSeverity.CRITICAL]:
            tasks.append(self._send_critical_alert(formatted))

        await asyncio.gather(*tasks, return_exceptions=True)

    def _format_alert(self, message: str, severity: AlertSeverity, context: dict) -> str:
        emoji_map = {
            AlertSeverity.INFO: "‚ÑπÔ∏è",
            AlertSeverity.WARNING: "‚ö†Ô∏è",
            AlertSeverity.ERROR: "‚ùå",
            AlertSeverity.CRITICAL: "üö®",
        }

        lines = [
            f"{emoji_map[severity]} **{severity.value.upper()}**",
            f"**Message:** {message}",
            f"**Time:** {datetime.now().isoformat()}",
        ]

        if context:
            lines.append("**Context:**")
            for key, value in context.items():
                lines.append(f"  ‚Ä¢ {key}: {value}")

        return "\n".join(lines)
```

### 4.2 Metrics Collection [MEDIUM]

```python
# monitoring/metrics.py
import time
from contextlib import contextmanager
from typing import Dict

class MetricsCollector:
    """Collect and export metrics"""

    def __init__(self):
        self.counters: Dict[str, int] = {}
        self.timers: Dict[str, list[float]] = {}
        self.gauges: Dict[str, float] = {}

    def increment(self, metric: str, value: int = 1, labels: Dict = None):
        """Increment counter"""
        key = self._make_key(metric, labels)
        self.counters[key] = self.counters.get(key, 0) + value

    @contextmanager
    def timer(self, metric: str, labels: Dict = None):
        """Time a code block"""
        start = time.perf_counter()
        try:
            yield
        finally:
            duration = time.perf_counter() - start
            key = self._make_key(metric, labels)
            if key not in self.timers:
                self.timers[key] = []
            self.timers[key].append(duration)

    def set_gauge(self, metric: str, value: float, labels: Dict = None):
        """Set gauge value"""
        key = self._make_key(metric, labels)
        self.gauges[key] = value

    def export_prometheus(self) -> str:
        """Export metrics in Prometheus format"""
        lines = []

        # Counters
        for key, value in self.counters.items():
            lines.append(f"{key} {value}")

        # Timers (as histograms)
        for key, values in self.timers.items():
            if values:
                lines.append(f"{key}_sum {sum(values)}")
                lines.append(f"{key}_count {len(values)}")
                lines.append(f"{key}_avg {sum(values)/len(values)}")

        # Gauges
        for key, value in self.gauges.items():
            lines.append(f"{key} {value}")

        return "\n".join(lines)

    def _make_key(self, metric: str, labels: Dict = None) -> str:
        if not labels:
            return metric
        label_str = ",".join(f'{k}="{v}"' for k, v in labels.items())
        return f"{metric}{{{label_str}}}"
```

### 4.3 Health Check Endpoint [LOW]

```python
# monitoring/healthcheck.py
from datetime import datetime, timedelta
from typing import Dict, List

class HealthCheckService:
    """Comprehensive health checking"""

    def __init__(self, config: Config):
        self.config = config
        self.checks: Dict[str, HealthCheck] = {
            "database": DatabaseHealthCheck(),
            "gemini_api": GeminiHealthCheck(),
            "telegram_api": TelegramHealthCheck(),
            "disk_space": DiskSpaceHealthCheck(),
            "memory": MemoryHealthCheck(),
        }

    async def check_health(self) -> Dict:
        """Run all health checks"""
        results = {}

        for name, check in self.checks.items():
            try:
                result = await check.check()
                results[name] = {
                    "status": "healthy" if result.is_healthy else "unhealthy",
                    "message": result.message,
                    "latency_ms": result.latency_ms,
                }
            except Exception as e:
                results[name] = {
                    "status": "error",
                    "message": str(e),
                }

        # Overall status
        all_healthy = all(
            r.get("status") == "healthy" for r in results.values()
        )

        return {
            "status": "healthy" if all_healthy else "unhealthy",
            "timestamp": datetime.now().isoformat(),
            "checks": results,
        }
```

---

## üìÖ –§–ê–ó–ê 5: –†–ï–§–ê–ö–¢–û–†–ò–ù–ì –ò –ö–ê–ß–ï–°–¢–í–û –ö–û–î–ê (–ù–µ–¥–µ–ª–∏ 7-8)

### 5.1 –†–∞–∑–±–∏–≤–∫–∞ –±–æ–ª—å—à–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π [MEDIUM]

```python
# services/news_processor_refactored.py

class NewsProcessor:
    """Refactored —Å –º–µ–Ω—å—à–∏–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏"""

    async def process_all_categories(self, client: TelegramClient):
        """Main processing - —Ç–µ–ø–µ—Ä—å —á–∏—Ç–∞–µ–º–∞—è"""
        # 1. Load messages
        messages = await self._load_unprocessed_messages()

        # 2. Filter by keywords
        categorized = await self._categorize_messages(messages)

        # 3. Remove duplicates
        unique = await self._filter_duplicates_for_all(categorized)

        # 4. AI selection
        selected = await self._ai_select_for_all(unique)

        # 5. Moderation
        approved = await self._moderate_all(selected, client)

        # 6. Publish
        await self._publish_all(approved, client)

        # 7. Cleanup
        await self._mark_processed(messages)

    async def _load_unprocessed_messages(self) -> List[Message]:
        """Step 1: Load messages"""
        cutoff = datetime.now() - timedelta(hours=self.config.hours_back)
        return await asyncio.to_thread(
            self.db.get_unprocessed_messages,
            cutoff_time=cutoff
        )

    async def _categorize_messages(
        self,
        messages: List[Message]
    ) -> Dict[Category, List[Message]]:
        """Step 2: Categorize by keywords"""
        result = defaultdict(list)

        for message in messages:
            category = self._determine_category(message.text)
            if category:
                result[category].append(message)

        return dict(result)

    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã
```

### 5.2 –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è [LOW]

```python
# services/chunking_service.py
class ChunkingService:
    """Centralized chunking logic"""

    def __init__(self, max_chunk_size: int = 1000):
        self.max_chunk_size = max_chunk_size

    def chunk_messages(
        self,
        messages: List[Dict],
        size_calculator = len
    ) -> List[List[Dict]]:
        """Universal chunking logic"""
        chunks = []
        current_chunk = []
        current_size = 0

        for message in messages:
            message_size = size_calculator(message)

            if current_size + message_size > self.max_chunk_size:
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = [message]
                current_size = message_size
            else:
                current_chunk.append(message)
                current_size += message_size

        if current_chunk:
            chunks.append(current_chunk)

        return chunks
```

### 5.3 –£–ª—É—á—à–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è [MEDIUM]

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è
pytest --cov=. --cov-report=html --cov-report=term --cov-fail-under=80

# –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:
- services/telegram_listener.py - input validation, error handling
- services/gemini_client.py - retry logic, circuit breaker
- database/db.py - concurrency, transactions
- utils/config.py - validation, profile loading
```

---

## üìã –ü–†–ò–û–†–ò–¢–ò–ó–ê–¶–ò–Ø –ó–ê–î–ê–ß

### Sprint 1 (–ù–µ–¥–µ–ª—è 1) - CRITICAL SECURITY
- [ ] –û—Ç–æ–∑–≤–∞—Ç—å –≤—Å–µ API –∫–ª—é—á–∏
- [ ] –£–¥–∞–ª–∏—Ç—å .env –∏–∑ git –∏—Å—Ç–æ—Ä–∏–∏
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å secrets management
- [ ] –î–æ–±–∞–≤–∏—Ç—å input sanitization
- [ ] –ù–∞–ø–∏—Å–∞—Ç—å security tests

### Sprint 2 (–ù–µ–¥–µ–ª–∏ 2-3) - RELIABILITY
- [ ] Implement Circuit Breaker
- [ ] –£–ª—É—á—à–∏—Ç—å Rate Limiting
- [ ] –î–æ–±–∞–≤–∏—Ç—å retry strategies
- [ ] Async queue –¥–ª—è –ë–î

### Sprint 3 (–ù–µ–¥–µ–ª–∏ 4-5) - PERFORMANCE
- [ ] Connection pooling
- [ ] Response caching
- [ ] Batch processing
- [ ] Performance profiling

### Sprint 4 (–ù–µ–¥–µ–ª—è 6) - MONITORING
- [ ] Alerting system
- [ ] Metrics collection
- [ ] Health checks
- [ ] Dashboards

### Sprint 5 (–ù–µ–¥–µ–ª–∏ 7-8) - QUALITY
- [ ] Refactor large functions
- [ ] Remove duplication
- [ ] Improve test coverage
- [ ] Documentation

---

## üìä –ú–ï–¢–†–ò–ö–ò –£–°–ü–ï–•–ê

### –ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
- [ ] Test coverage > 80%
- [ ] –í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω—ã
- [ ] Response time < 2s –¥–ª—è 95% –∑–∞–ø—Ä–æ—Å–æ–≤
- [ ] Uptime > 99.9%
- [ ] Zero security incidents

### –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
- [ ] Code review checklist –≤–Ω–µ–¥—Ä–µ–Ω
- [ ] CI/CD pipeline —Å security checks
- [ ] Monitoring dashboards –∞–∫—Ç–∏–≤–Ω—ã
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–∞
- [ ] Team onboarding < 1 –¥–µ–Ω—å

---

## üõ†Ô∏è –ò–ù–°–¢–†–£–ú–ï–ù–¢–´ –ò –¢–ï–•–ù–û–õ–û–ì–ò–ò

### Security:
- `bandit` - Python security linter
- `safety` - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –Ω–∞ —É—è–∑–≤–∏–º–æ—Å—Ç–∏
- `pip-audit` - –ê—É–¥–∏—Ç Python packages
- GitHub Dependabot

### Quality:
- `black` - Code formatter
- `ruff` - Fast Python linter
- `mypy` - Static type checking
- `pre-commit` - Git hooks

### Monitoring:
- Prometheus + Grafana
- Sentry –¥–ª—è error tracking
- Custom Telegram alerts

### Testing:
- `pytest` + `pytest-asyncio`
- `coverage.py`
- `hypothesis` –¥–ª—è property-based testing
- `locust` –¥–ª—è load testing

---

## üìù –ö–û–ù–¢–†–û–õ–¨–ù–´–ô –ß–ï–ö–õ–ò–°–¢

### –ü–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º —Ä–µ–ª–∏–∑–æ–º:
- [ ] –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] Security scan –ø—Ä–æ–π–¥–µ–Ω
- [ ] Performance benchmarks –≤ –Ω–æ—Ä–º–µ
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞
- [ ] CHANGELOG –æ–±–Ω–æ–≤–ª–µ–Ω
- [ ] Code review –ø—Ä–æ–π–¥–µ–Ω
- [ ] Monitoring –Ω–∞—Å—Ç—Ä–æ–µ–Ω

### Code Review Checklist:
- [ ] –ù–µ—Ç hardcoded secrets
- [ ] SQL –∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω—ã
- [ ] Input –¥–∞–Ω–Ω—ã–µ —Å–∞–Ω–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω—ã
- [ ] Errors –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è gracefully
- [ ] –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–¥–µ–∫–≤–∞—Ç–Ω–æ–µ
- [ ] –¢–µ—Å—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω—ã
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞

---

## üéØ –§–ò–ù–ê–õ–¨–ù–ê–Ø –¶–ï–õ–¨

–ü—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å TG News Bot –≤ **production-grade —Å–∏—Å—Ç–µ–º—É** —Å:
- **99.9% uptime**
- **Zero security vulnerabilities**
- **< 2s response time**
- **80%+ test coverage**
- **Comprehensive monitoring**
- **Clean, maintainable code**

---

## üìö –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –†–ï–°–£–†–°–´

- [OWASP Python Security](https://owasp.org/www-project-python-security/)
- [The Twelve-Factor App](https://12factor.net/)
- [Google SRE Book](https://sre.google/sre-book/table-of-contents/)
- [Python Best Practices](https://docs.python-guide.org/)

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025-10-27
**–°–ª–µ–¥—É—é—â–∏–π review:** 2025-11-03
**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π:** Tech Lead

> üí° **–ü–æ–º–Ω–∏—Ç–µ:** –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å - —ç—Ç–æ –Ω–µ —Ä–∞–∑–æ–≤–∞—è –∑–∞–¥–∞—á–∞, –∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å!