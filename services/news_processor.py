"""–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""

import asyncio
from datetime import datetime, timedelta

import numpy as np
from telethon import TelegramClient
from telethon.errors import FloodWaitError

from database.db import Database
from models.category import Category
from services.embeddings import EmbeddingService
from services.gemini_client import GeminiClient
from services.llm import create_llm_client, LLMClient
from services.auto_moderator import AutoModerator, ModerationResult
from utils.config import Config
from utils.constants import NUMBER_EMOJIS
from utils.formatters import ensure_post_fields
from utils.logger import get_logger
from utils.advanced_rate_limiter import MultiLevelRateLimiter, AdaptiveRateLimiter
from utils.telegram_helpers import safe_connect
from utils.timezone import now_msk

logger = get_logger(__name__)


class NewsProcessor:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""

    # –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Telegram API
    TELEGRAM_MESSAGE_LIMIT = 4096  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram
    PREVIEW_SAFETY_MARGIN = 50     # –ó–∞–ø–∞—Å —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
    MAX_MESSAGE_SIZE = 100000      # 100KB - –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥—è—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (security)

    def __init__(self, config: Config):
        self.config = config
        self.db = Database(config.db_path, **config.database_settings())
        self._embedding_service: EmbeddingService | None = None
        self._gemini_client: GeminiClient | None = None
        self._llm_client: LLMClient | None = None

        # Security: –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π rate limiter –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç Telegram API limits
        # –í–∫–ª—é—á–∞–µ—Ç global limits, burst protection, per-chat limits
        base_limiter = MultiLevelRateLimiter()
        self._rate_limiter = AdaptiveRateLimiter(base_limiter)

        # –ö—ç—à –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (CR-H1)
        self._cached_published_embeddings: list[tuple[int, any]] | None = None
        # QA-7: _cached_base_messages —É–¥–∞–ª—ë–Ω –∫–∞–∫ –º—ë—Ä—Ç–≤—ã–π –∫–æ–¥ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)

        # FIX-DUPLICATE-1: TTL-based cache invalidation –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–∞–º–∏
        self._cache_timestamp: datetime | None = None
        self._cache_ttl_seconds: int = config.get("cache.ttl_seconds", 1800)  # 30 –º–∏–Ω—É—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        # QA-4: –ö—ç—à –º–∞—Ç—Ä–∏—Ü—ã embeddings –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ O(N¬≤) ‚Üí O(N)
        self._published_embeddings_matrix: np.ndarray | None = None
        self._published_embeddings_ids: list[int] | None = None

        self._embedding_model_name = config.get(
            "embeddings.model", "paraphrase-multilingual-MiniLM-L12-v2"
        )
        self._embedding_local_path = config.get("embeddings.local_path")
        self._embedding_allow_remote = config.get("embeddings.allow_remote_download", True)
        self._embedding_enable_fallback = config.get("embeddings.enable_fallback", True)
        self._gemini_model_name = config.get("gemini.model", "gemini-1.5-flash")

        self.global_exclude_keywords = [
            keyword.lower() for keyword in config.get("filters.exclude_keywords", []) if keyword
        ]

        # U4: Backwards compatibility - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±–æ–∏—Ö –∫–ª—é—á–µ–π (categories –∏ marketplaces)
        raw_marketplaces = config.get("categories") or config.get("marketplaces", [])
        if isinstance(raw_marketplaces, dict):
            raw_marketplaces = [
                {
                    "name": name,
                    **(raw_marketplaces[name] or {}),
                }
                for name in raw_marketplaces
            ]

        self.categories: dict[str, Category] = {}
        for mp_cfg in raw_marketplaces:
            if not isinstance(mp_cfg, dict):
                continue
            data = dict(mp_cfg)
            data.setdefault("enabled", True)
            try:
                category = Category(**data)
            except TypeError as exc:
                logger.error(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {mp_cfg}: {exc}")
                continue
            category.combined_exclude_keywords_lower = list(
                dict.fromkeys(category.exclude_keywords_lower + self.global_exclude_keywords)
            )
            self.categories[category.name] = category

        if not self.categories:
            logger.warning("–í –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏")

        self.all_exclude_keywords_lower = set(self.global_exclude_keywords)
        for category in self.categories.values():
            self.all_exclude_keywords_lower.update(category.combined_exclude_keywords_lower)

        self.category_names = list(self.categories.keys())

        default_channel = next(
            (mp.target_channel for mp in self.categories.values() if mp.target_channel),
            None,
        )

        self.all_digest_enabled = config.get("channels.all_digest.enabled", True)
        self.all_digest_channel = config.get(
            "channels.all_digest.target_channel",
            default_channel,
        )
        counts_config = config.get("channels.all_digest.category_counts", {})
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —á–∏—Ç–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞)
        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª—é–±—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –Ω–µ —Ç–æ–ª—å–∫–æ marketplace-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ
        self.all_digest_counts = dict(counts_config) if counts_config else {}
        descriptions_config = config.get("channels.all_digest.category_descriptions", {})
        self.all_digest_descriptions = dict(descriptions_config) if descriptions_config else {}

        self.publication_header_template = config.get(
            "publication.header_template",
            "üì∞ –ì–ª–∞–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ {date}",
        )
        self.publication_footer_template = config.get("publication.footer_template", "")
        self.publication_preview_channel = config.get("publication.preview_channel")
        self.publication_notify_account = config.get("publication.notify_account")

        # FIX-DUPLICATE-2: –°–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥ —Å 0.85 –¥–æ 0.78 –¥–ª—è –ª—É—á—à–µ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        self.duplicate_threshold = config.get("processor.duplicate_threshold", 0.78)

        # FIX-DUPLICATE-4: DBSCAN clustering –¥–ª—è –ª—É—á—à–µ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        self.use_dbscan = config.get("processor.use_dbscan", False)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–∫–ª—é—á–µ–Ω (backwards compatibility)
        self.dbscan_eps = config.get("processor.dbscan_eps", 0.22)  # eps = 1 - similarity_threshold (1 - 0.78 = 0.22)
        self.dbscan_min_samples = config.get("processor.dbscan_min_samples", 2)  # –ú–∏–Ω–∏–º—É–º 2 —Ç–æ—á–∫–∏ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞

        # FIX-DUPLICATE-6: –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º–æ–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        self.duplicate_time_window_days = config.get("processor.duplicate_time_window_days", 60)  # 60 –¥–Ω–µ–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

        self.processor_top_n = config.get("processor.top_n", 10)
        self.processor_exclude_count = config.get("processor.exclude_count", 5)
        if not isinstance(self.processor_top_n, int) or self.processor_top_n <= 0:
            logger.warning(
                "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ processor.top_n=%s, –∏—Å–ø–æ–ª—å–∑—É–µ–º 10",
                self.processor_top_n,
            )
            self.processor_top_n = 10
        if not isinstance(self.processor_exclude_count, int) or self.processor_exclude_count < 0:
            logger.warning(
                "–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ processor.exclude_count=%s, –∏—Å–ø–æ–ª—å–∑—É–µ–º 5",
                self.processor_exclude_count,
            )
            self.processor_exclude_count = 5
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ—Ä–∞—Ü–∏–∏
        # auto_moderation: True = –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, False = —Å —Ä—É—á–Ω—ã–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º
        self.auto_moderation = config.get("moderation.auto", True)
        self.moderation_enabled = config.get("moderation.enabled", True)
        self.moderation_timeout_hours = config.get("moderation.timeout_hours", 2)
        # final_top_n: —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ—Å–ª–µ –º–æ–¥–µ—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
        self.final_top_n = config.get("moderation.final_top_n", 10)

        # –ö—ç—à –¥–ª—è AutoModerator
        self._auto_moderator: AutoModerator | None = None

    @property
    def auto_moderator(self) -> AutoModerator:
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≤—Ç–æ–º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞"""
        if self._auto_moderator is None:
            self._auto_moderator = AutoModerator(
                embeddings_service=self.embeddings,
                duplicate_threshold=self.duplicate_threshold,
                final_top_n=self.final_top_n,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
            )
        return self._auto_moderator

    @property
    def embeddings(self) -> EmbeddingService:
        if self._embedding_service is None:
            self._embedding_service = EmbeddingService(
                model_name=self._embedding_model_name,
                local_path=self._embedding_local_path,
                allow_remote_download=self._embedding_allow_remote,
                enable_fallback=self._embedding_enable_fallback,
            )
        return self._embedding_service

    @property
    def gemini(self) -> GeminiClient:
        if self._gemini_client is None:
            self._gemini_client = GeminiClient(
                api_key=self.config.gemini_api_key,
                model_name=self._gemini_model_name,
                prompt_loader=self.config.load_prompt,
            )
        return self._gemini_client

    @property
    def llm_client(self) -> LLMClient:
        if self._llm_client is None:
            self._llm_client = create_llm_client(self.config)
        return self._llm_client

    # –°–¢–ê–†–ê–Ø –°–ò–°–¢–ï–ú–ê –£–î–ê–õ–ï–ù–ê: –º–µ—Ç–æ–¥ process_category() –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ 3-–∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —á–µ—Ä–µ–∑ process_all_categories()

    def _filter_by_keywords(
        self, messages: list[dict], keywords_lower: list[str], exclude_keywords_lower: list[str]
    ) -> tuple[list[dict], dict[int, str]]:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º

        Returns:
            Tuple of (filtered_messages, rejected_reasons)
            where rejected_reasons maps message_id -> rejection_reason
        """
        filtered = []
        rejected = {}

        for msg in messages:
            text_lower = msg["text"].lower()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–∫–ª—é—á–∞—é—â–∏–µ —Å–ª–æ–≤–∞
            if exclude_keywords_lower and any(
                exclude in text_lower for exclude in exclude_keywords_lower
            ):
                rejected[msg["id"]] = "rejected_by_exclude_keywords"
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∫–ª—é—á–∞—é—â–∏–µ —Å–ª–æ–≤–∞
            if keywords_lower and not any(keyword in text_lower for keyword in keywords_lower):
                rejected[msg["id"]] = "rejected_by_keywords_mismatch"
                continue

            filtered.append(msg)

        return filtered, rejected

    async def filter_duplicates(self, messages: list[dict]) -> tuple[list[dict], dict[int, str]]:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ embeddings

        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ (CR-H1): –∑–∞–≥—Ä—É–∂–∞–µ–º published_embeddings –æ–¥–∏–Ω —Ä–∞–∑ –∏ –∫—ç—à–∏—Ä—É–µ–º
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ (CR-C5): –∏—Å–ø–æ–ª—å–∑—É–µ–º batch encoding –≤–º–µ—Å—Ç–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ encode
        –£–ª—É—á—à–µ–Ω–æ: –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è (published + intra-batch)

        Returns:
            Tuple of (unique_messages, rejected_reasons)
            where rejected_reasons maps message_id -> rejection_reason
        """
        unique = []
        rejected = {}

        if not messages:
            return unique, rejected

        # CR-H1: –ó–∞–≥—Ä—É–∂–∞–µ–º published embeddings –æ–¥–∏–Ω —Ä–∞–∑ –∏ –∫—ç—à–∏—Ä—É–µ–º
        # FIX-DUPLICATE-1: –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL –∫—ç—à–∞ –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –µ—Å–ª–∏ —É—Å—Ç–∞—Ä–µ–ª
        # Sprint 6.3: –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–∏–π –¥–æ—Å—Ç—É–ø –∫ –ë–î
        cache_needs_reload = False
        if self._cached_published_embeddings is None:
            cache_needs_reload = True
            logger.debug("–ö—ç—à embeddings –ø—É—Å—Ç, —Ç—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∫–∞")
        elif self._cache_timestamp is None:
            cache_needs_reload = True
            logger.debug("Timestamp –∫—ç—à–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞")
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç –∫—ç—à–∞
            cache_age_seconds = (datetime.now() - self._cache_timestamp).total_seconds()
            if cache_age_seconds > self._cache_ttl_seconds:
                cache_needs_reload = True
                logger.info(
                    f"–ö—ç—à embeddings —É—Å—Ç–∞—Ä–µ–ª (–≤–æ–∑—Ä–∞—Å—Ç: {cache_age_seconds:.1f}—Å, TTL: {self._cache_ttl_seconds}—Å), "
                    f"–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –ë–î"
                )

        if cache_needs_reload:
            # FIX-DUPLICATE-6: –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º–æ–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ –≤–º–µ—Å—Ç–æ —Ö–∞—Ä–¥–∫–æ–¥–∞ 60
            self._cached_published_embeddings = await asyncio.to_thread(
                self.db.get_published_embeddings, days=self.duplicate_time_window_days
            )
            self._cache_timestamp = datetime.now()
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É embeddings –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–µ –∫—ç—à–∞
            self._published_embeddings_matrix = None
            self._published_embeddings_ids = None
            logger.info(
                f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self._cached_published_embeddings)} published embeddings –≤ –∫—ç—à "
                f"(TTL: {self._cache_ttl_seconds}—Å)"
            )

        # QA-4: –°—Ç—Ä–æ–∏–º –º–∞—Ç—Ä–∏—Ü—É embeddings –æ–¥–∏–Ω —Ä–∞–∑ –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
        # Sprint 6.3.4: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à –Ω–∞–ø—Ä—è–º—É—é, –±–µ–∑ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        if self._published_embeddings_matrix is None and self._cached_published_embeddings:
            self._published_embeddings_ids = [post_id for post_id, _ in self._cached_published_embeddings]
            self._published_embeddings_matrix = np.array([emb for _, emb in self._cached_published_embeddings])
            logger.debug(
                f"QA-4: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ embeddings {self._published_embeddings_matrix.shape} "
                f"–¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"
            )

        # CR-C5: –ë–∞—Ç—á–µ–≤–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å—Ä–∞–∑—É (async, non-blocking)
        texts = [msg["text"] for msg in messages]
        embeddings_array = await self.embeddings.encode_batch_async(texts, batch_size=32)
        logger.debug(f"CR-C5: Batch encoded {len(texts)} messages (shape: {embeddings_array.shape})")

        # –≠–¢–ê–ü 1: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–º–∏
        unique_from_published = []
        unique_embeddings = []

        for msg, embedding in zip(messages, embeddings_array):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã (inline –≤–º–µ—Å—Ç–æ db.check_duplicate)
            # Sprint 6.3.4: —É–¥–∞–ª—ë–Ω –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç published_embeddings
            is_duplicate = self._check_duplicate_inline(
                embedding, self.duplicate_threshold
            )

            if is_duplicate:
                rejected[msg["id"]] = "is_duplicate"
                continue

            unique_from_published.append(msg)
            unique_embeddings.append(embedding)

        logger.debug(
            f"–ü–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å published: {len(unique_from_published)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö "
            f"({len(rejected)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)"
        )

        # –≠–¢–ê–ü 2 (–ù–û–í–û–ï): –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –≤–Ω—É—Ç—Ä–∏ –±–∞—Ç—á–∞ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        # –≠—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∫–æ–≥–¥–∞ –æ–¥–Ω–∞ –Ω–æ–≤–æ—Å—Ç—å –ø–æ–ø–∞–ª–∞ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–Ω–∞–ª–æ–≤
        intra_batch_duplicates = 0
        seen_embeddings = []

        for msg, embedding in zip(unique_from_published, unique_embeddings):
            if not seen_embeddings:
                # –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤—Å–µ–≥–¥–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ
                unique.append(msg)
                seen_embeddings.append(embedding)
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º similarity —Å —É–∂–µ –ø—Ä–∏–Ω—è—Ç—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –∏–∑ –±–∞—Ç—á–∞
            seen_matrix = np.array(seen_embeddings)
            similarities = self.embeddings.batch_cosine_similarity(embedding, seen_matrix)
            max_similarity = np.max(similarities) if len(similarities) > 0 else 0.0

            if max_similarity >= self.duplicate_threshold:
                # –ù–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç –≤–Ω—É—Ç—Ä–∏ –±–∞—Ç—á–∞
                rejected[msg["id"]] = "intra_batch_duplicate"
                intra_batch_duplicates += 1
                logger.debug(
                    f"Intra-batch –¥—É–±–ª–∏–∫–∞—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω: msg_id={msg['id']}, "
                    f"similarity={max_similarity:.3f}"
                )
            else:
                # –£–Ω–∏–∫–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                unique.append(msg)
                seen_embeddings.append(embedding)

        logger.info(
            f"–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(unique)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö, "
            f"{len(rejected)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–∏–∑ –Ω–∏—Ö {intra_batch_duplicates} –≤–Ω—É—Ç—Ä–∏ –±–∞—Ç—á–∞)"
        )

        return unique, rejected

    async def deduplicate_selected_posts(
        self, posts: list[dict], threshold: float = 0.78
    ) -> tuple[list[dict], list[dict]]:
        """
        –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö Gemini –Ω–æ–≤–æ—Å—Ç–µ–π –ø–µ—Ä–µ–¥ –º–æ–¥–µ—Ä–∞—Ü–∏–µ–π

        –î–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è:
        1. –¢–æ—á–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ source_message_id (–æ–¥–∏–Ω raw_message –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤—ã–±—Ä–∞–Ω –¥–≤–∞–∂–¥—ã)
        2. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ embeddings (–ø–æ—Ö–æ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤)

        Args:
            posts: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ—Å–ª–µ –æ—Ç–±–æ—Ä–∞ Gemini (—Å title, description)
            threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (FIX-DUPLICATE-2: —Å–Ω–∏–∂–µ–Ω —Å 0.85 –¥–æ 0.78 –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)

        Returns:
            Tuple of (unique_posts, duplicates)
        """
        if not posts:
            return [], []

        duplicates = []

        # –≠–¢–ê–ü 1: –¢–æ—á–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ source_message_id
        # Gemini –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ (–∏–∑ —Ä–∞–∑–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
        seen_source_ids: set[int] = set()
        unique_by_id = []
        id_duplicates = 0

        for post in posts:
            source_id = post.get("source_message_id")
            if source_id is not None and source_id in seen_source_ids:
                duplicates.append(post)
                id_duplicates += 1
                logger.debug(
                    f"üîç –î—É–±–ª–∏–∫–∞—Ç –ø–æ source_message_id={source_id}: '{post.get('title', '')[:40]}...'"
                )
                continue
            if source_id is not None:
                seen_source_ids.add(source_id)
            unique_by_id.append(post)

        if id_duplicates > 0:
            logger.info(f"üîç –£–¥–∞–ª–µ–Ω–æ {id_duplicates} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ source_message_id")

        # –≠–¢–ê–ü 2: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ embeddings
        # –°–æ–∑–¥–∞—ë–º embeddings –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π text –¥–ª—è —Ç–æ—á–Ω–æ–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (LLM-–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ title/description –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è)
        texts = [
            post.get('text', f"{post.get('title', '')} {post.get('description', '')}")
            for post in unique_by_id
        ]
        embeddings_array = await self.embeddings.encode_batch_async(texts, batch_size=32)

        # FIX-DUPLICATE-4: –ò—Å–ø–æ–ª—å–∑—É–µ–º DBSCAN –∏–ª–∏ fixed threshold –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if self.use_dbscan:
            logger.debug(
                f"Post-Gemini DBSCAN –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: –ø—Ä–æ–≤–µ—Ä—è–µ–º {len(unique_by_id)} –Ω–æ–≤–æ—Å—Ç–µ–π "
                f"(eps={self.dbscan_eps}, min_samples={self.dbscan_min_samples})"
            )
            unique, semantic_dups = self._deduplicate_with_dbscan(unique_by_id, embeddings_array)
        else:
            logger.debug(
                f"Post-Gemini threshold –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: –ø—Ä–æ–≤–µ—Ä—è–µ–º {len(unique_by_id)} –Ω–æ–≤–æ—Å—Ç–µ–π (–ø–æ—Ä–æ–≥={threshold})"
            )
            unique, semantic_dups = self._deduplicate_with_threshold(unique_by_id, embeddings_array, threshold)

        duplicates.extend(semantic_dups)
        semantic_duplicates = len(semantic_dups)

        logger.info(
            f"‚úÖ Post-Gemini –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: {len(unique)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö, "
            f"{len(duplicates)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–æ ({id_duplicates} –ø–æ ID, {semantic_duplicates} —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö)"
        )

        return unique, duplicates

    def _deduplicate_with_dbscan(
        self, posts: list[dict], embeddings_array: np.ndarray
    ) -> tuple[list[dict], list[dict]]:
        """
        FIX-DUPLICATE-4: DBSCAN-based –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç DBSCAN (Density-Based Spatial Clustering) –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        –ø–æ—Ö–æ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π. –ò–∑ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞ –æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å.

        –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –Ω–∞–¥ fixed threshold:
        - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç –∫–ª–∞—Å—Ç–µ—Ä—ã –ø–æ—Ö–æ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
        - –£—á–∏—Ç—ã–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é –ø–ª–æ—Ç–Ω–æ—Å—Ç—å (5 –ø–æ—Ö–æ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π = 1 –∫–ª–∞—Å—Ç–µ—Ä)
        - Outliers (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏) –æ—Å—Ç–∞—é—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏

        Args:
            posts: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
            embeddings_array: Numpy array —Å embeddings (shape: [n_posts, embedding_dim])

        Returns:
            Tuple of (unique_posts, duplicates)
        """
        if len(posts) == 0:
            return [], []

        if len(posts) == 1:
            # –û–¥–∏–Ω –ø–æ—Å—Ç –≤—Å–µ–≥–¥–∞ —É–Ω–∏–∫–∞–ª–µ–Ω
            return posts, []

        try:
            from sklearn.cluster import DBSCAN
        except ImportError:
            logger.warning(
                "sklearn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback –Ω–∞ fixed threshold –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é. "
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install scikit-learn"
            )
            # Fallback –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º–µ—Ç–æ–¥
            return self._deduplicate_with_threshold(posts, embeddings_array, self.duplicate_threshold)

        # –ó–∞–ø—É—Å–∫–∞–µ–º DBSCAN
        dbscan = DBSCAN(
            eps=self.dbscan_eps,
            min_samples=self.dbscan_min_samples,
            metric="cosine",
        )
        labels = dbscan.fit_predict(embeddings_array)

        logger.debug(
            f"DBSCAN –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: –Ω–∞–π–¥–µ–Ω–æ {len(set(labels))} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ "
            f"(eps={self.dbscan_eps}, min_samples={self.dbscan_min_samples})"
        )

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Å—Ç—ã –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
        unique = []
        duplicates = []
        cluster_representatives: dict[int, int] = {}  # cluster_id -> index of representative

        for idx, (post, label) in enumerate(zip(posts, labels)):
            if label == -1:
                # Outlier (—à—É–º) - —Å—á–∏—Ç–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–º
                unique.append(post)
                logger.debug(f"DBSCAN: outlier #{idx} '{post.get('title', '')[:40]}...' - —É–Ω–∏–∫–∞–ª—å–Ω—ã–π")
            else:
                # –≠–ª–µ–º–µ–Ω—Ç –∫–ª–∞—Å—Ç–µ—Ä–∞
                if label not in cluster_representatives:
                    # –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–ª–∞—Å—Ç–µ—Ä–∞ - –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å
                    cluster_representatives[label] = idx
                    unique.append(post)
                    logger.debug(
                        f"DBSCAN: –∫–ª–∞—Å—Ç–µ—Ä {label}, –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å #{idx} '{post.get('title', '')[:40]}...'"
                    )
                else:
                    # –î—É–±–ª–∏–∫–∞—Ç - –Ω–µ –ø–µ—Ä–≤—ã–π –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ
                    duplicates.append(post)
                    representative_idx = cluster_representatives[label]
                    logger.info(
                        f"üîç DBSCAN –¥—É–±–ª–∏–∫–∞—Ç: '{post.get('title', '')[:50]}...' "
                        f"–≤ –∫–ª–∞—Å—Ç–µ—Ä–µ {label} (–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å #{representative_idx})"
                    )

        logger.info(
            f"‚úÖ DBSCAN –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: {len(unique)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö, "
            f"{len(duplicates)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–æ"
        )

        return unique, duplicates

    def _deduplicate_with_threshold(
        self, posts: list[dict], embeddings_array: np.ndarray, threshold: float
    ) -> tuple[list[dict], list[dict]]:
        """
        –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å fixed threshold (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ fallback)

        Args:
            posts: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
            embeddings_array: Numpy array —Å embeddings
            threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏

        Returns:
            Tuple of (unique_posts, duplicates)
        """
        unique = []
        duplicates = []
        seen_embeddings = []

        for post, embedding in zip(posts, embeddings_array):
            if not seen_embeddings:
                unique.append(post)
                seen_embeddings.append(embedding)
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º similarity —Å —É–∂–µ –ø—Ä–∏–Ω—è—Ç—ã–º–∏ –ø–æ—Å—Ç–∞–º–∏
            seen_matrix = np.array(seen_embeddings)
            similarities = self.embeddings.batch_cosine_similarity(embedding, seen_matrix)
            max_similarity = np.max(similarities) if len(similarities) > 0 else 0.0

            if max_similarity >= threshold:
                duplicates.append(post)
                duplicate_idx = np.argmax(similarities)
                logger.info(
                    f"üîç Threshold –¥—É–±–ª–∏–∫–∞—Ç: '{post.get('title', '')[:50]}...' "
                    f"–ø–æ—Ö–æ–∂–∞ –Ω–∞ #{duplicate_idx+1} (similarity={max_similarity:.3f})"
                )
            else:
                unique.append(post)
                seen_embeddings.append(embedding)

        return unique, duplicates

    def _update_published_cache(self, post_ids: list[int], embeddings: list[np.ndarray]):
        """
        QA-2: –û–±–Ω–æ–≤–∏—Ç—å –∫—ç—à published embeddings –ø–æ—Å–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        QA-4: –¢–∞–∫–∂–µ –æ–±–Ω–æ–≤–ª—è–µ–º –º–∞—Ç—Ä–∏—Ü—É embeddings –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        FIX-DUPLICATE-1: –û–±–Ω–æ–≤–ª—è–µ–º timestamp –∫—ç—à–∞ –ø—Ä–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏

        –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ embeddings –≤ –∫—ç—à, —á—Ç–æ–±—ã –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ
        –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ —Ç–æ–º –∂–µ –∑–∞–ø—É—Å–∫–µ –º–æ–≥–ª–∏ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã.

        Args:
            post_ids: –°–ø–∏—Å–æ–∫ source_message_id –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
            embeddings: –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ embeddings
        """
        if self._cached_published_embeddings is None:
            # –ö—ç—à –µ—â—ë –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω - –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º
            self._cached_published_embeddings = []
            self._cache_timestamp = datetime.now()
            logger.debug("QA-2: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∫—ç—à published embeddings")

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ embeddings –≤ –∫—ç—à
        new_entries = list(zip(post_ids, embeddings))
        self._cached_published_embeddings.extend(new_entries)

        # FIX-DUPLICATE-1: –û–±–Ω–æ–≤–ª—è–µ–º timestamp –ø—Ä–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏
        # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —á—Ç–æ –∫—ç—à —Å—á–∏—Ç–∞–µ—Ç—Å—è —Å–≤–µ–∂–∏–º –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö embeddings
        self._cache_timestamp = datetime.now()

        # QA-4: –û–±–Ω–æ–≤–ª—è–µ–º –º–∞—Ç—Ä–∏—Ü—É embeddings –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ
        if self._published_embeddings_matrix is not None and len(embeddings) > 0:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–∞—Ç—Ä–∏—Ü–µ
            new_matrix = np.array(embeddings)
            self._published_embeddings_matrix = np.vstack([self._published_embeddings_matrix, new_matrix])
            self._published_embeddings_ids.extend(post_ids)

            logger.debug(
                f"QA-4: –û–±–Ω–æ–≤–ª–µ–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ embeddings, –Ω–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {self._published_embeddings_matrix.shape}"
            )

        logger.debug(
            f"QA-2: –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_entries)} embeddings –≤ –∫—ç—à. "
            f"–í—Å–µ–≥–æ –≤ –∫—ç—à–µ: {len(self._cached_published_embeddings)}"
        )

    def _check_duplicate_inline(
        self, embedding: np.ndarray, threshold: float = 0.78
    ) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç inline –±–µ–∑ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –ë–î (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è CR-H1)
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ (CR-C5): –∏—Å–ø–æ–ª—å–∑—É–µ–º batch_cosine_similarity –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ (QA-4): –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É –≤–º–µ—Å—Ç–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è
        –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ (Sprint 6.3.4): —É–¥–∞–ª—ë–Ω –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä published_embeddings
        FIX-DUPLICATE-2: –°–Ω–∏–∂–µ–Ω –ø–æ—Ä–æ–≥ —Å 0.85 –¥–æ 0.78

        Args:
            embedding: Embedding –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏

        Returns:
            True –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç
        """
        # QA-4: –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É –≤–º–µ—Å—Ç–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –∫–∞–∂–¥—ã–π —Ä–∞–∑
        if self._published_embeddings_matrix is None or len(self._published_embeddings_matrix) == 0:
            return False

        embedding_norm = np.linalg.norm(embedding)
        if embedding_norm == 0:
            logger.warning("–ü–æ–ª—É—á–µ–Ω embedding —Å –Ω—É–ª–µ–≤–æ–π –Ω–æ—Ä–º–æ–π –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
            return False

        # QA-4: –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—É—é –º–∞—Ç—Ä–∏—Ü—É (–ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫)
        # –í—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ similarity scores –∑–∞ –æ–¥–∏–Ω —Ä–∞–∑
        similarities = self.embeddings.batch_cosine_similarity(embedding, self._published_embeddings_matrix)

        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Å—Ö–æ–∂–µ—Å—Ç—å
        if len(similarities) > 0:
            max_similarity = np.max(similarities)
            if max_similarity >= threshold:
                # QA-4: –ù–∞—Ö–æ–¥–∏–º post_id –∏–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ IDs
                max_idx = np.argmax(similarities)
                post_id = self._published_embeddings_ids[max_idx]
                logger.debug(
                    f"–ù–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: post_id={post_id}, similarity={max_similarity:.3f}"
                )
                return True

        return False

    async def moderate_posts(
        self, client: TelegramClient, posts: list[dict], marketplace: str
    ) -> list[dict]:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é —á–µ—Ä–µ–∑ Telegram"""

        logger.info(f"üìã –û—Ç–ø—Ä–∞–≤–∫–∞ {len(posts)} –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é ({marketplace})")

        # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º ID –¥–ª—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏
        for idx, post in enumerate(posts, 1):
            post["moderation_id"] = idx

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏
        message = self._format_moderation_message(posts, marketplace)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –ª–∏—á–∫—É (–∏—Å–ø–æ–ª—å–∑—É–µ–º my_personal_account –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
        personal_account = self.config.my_personal_account
        await client.send_message(personal_account, message)

        logger.info(f"‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ {personal_account}")

        # TODO: –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ –ø–æ—Å—Ç—ã (–∞–≤—Ç–æ—É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ)
        return posts

    async def process_all_categories(self, client: TelegramClient):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –Ω–æ–≤–æ—Å—Ç–µ–π —Å 3-–∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π (5 WB + 5 Ozon + 5 –û–±—â–∏—Ö = 15)"""

        logger.info("=" * 80)
        logger.info("üì¶ –û–ë–†–ê–ë–û–¢–ö–ê –ù–û–í–û–°–¢–ï–ô: –í–°–ï –ö–ê–¢–ï–ì–û–†–ò–ò (3-–ö–ê–¢–ï–ì–û–†–ò–ô–ù–ê–Ø –°–ò–°–¢–ï–ú–ê)")
        logger.info("=" * 80)

        # Sprint 6.3: –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–∏–π –¥–æ—Å—Ç—É–ø –∫ –ë–î
        base_messages = await asyncio.to_thread(self.db.get_unprocessed_messages, hours=24)
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(base_messages)} –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")

        if not base_messages:
            logger.info("–ù–µ—Ç –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")
            return

        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–∏—á–∏–Ω –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
        all_rejected = {}

        # –®–ê–ì 2: –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≥–ª–æ–±–∞–ª—å–Ω—ã–º –∏—Å–∫–ª—é—á–∞—é—â–∏–º —Å–ª–æ–≤–∞–º
        filtered_messages = []
        for msg in base_messages:
            text_lower = msg["text"].lower()
            if self.all_exclude_keywords_lower and any(
                exclude in text_lower for exclude in self.all_exclude_keywords_lower
            ):
                all_rejected[msg["id"]] = "rejected_by_exclude_keywords"
                continue
            filtered_messages.append(msg)

        logger.info(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–π: {len(filtered_messages)} —Å–æ–æ–±—â–µ–Ω–∏–π")

        if not filtered_messages:
            # –ü–æ–º–µ—á–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–∫ processed
            # Sprint 6.4: –ë–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–º–µ—Å—Ç–æ N –≤—ã–∑–æ–≤–æ–≤
            updates = [
                {'message_id': msg_id, 'rejection_reason': reason}
                for msg_id, reason in all_rejected.items()
            ]
            await asyncio.to_thread(self.db.mark_as_processed_batch, updates)
            logger.info("–ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–π")
            return

        # –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        unique_messages, rejected_duplicates = await self.filter_duplicates(filtered_messages)
        all_rejected.update(rejected_duplicates)
        logger.info(f"–ü–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(unique_messages)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö")

        if not unique_messages:
            # –ü–æ–º–µ—á–∞–µ–º –≤—Å–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–∫ processed
            # Sprint 6.4: –ë–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–º–µ—Å—Ç–æ N –≤—ã–∑–æ–≤–æ–≤
            updates = [
                {
                    'message_id': msg_id,
                    'is_duplicate': (reason == "is_duplicate"),
                    'rejection_reason': reason
                }
                for msg_id, reason in all_rejected.items()
            ]
            await asyncio.to_thread(self.db.mark_as_processed_batch, updates)
            logger.warning("–í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —è–≤–ª—è—é—Ç—Å—è –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏")
            return

        # –®–ê–ì 4: –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å ‚Äî –ø–æ–ª—É—á–∞–µ–º –Ω–µ–¥–∞–≤–Ω–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–º—ã
        recently_published_raw = await asyncio.to_thread(
            self.db.get_recently_published_texts, 7, 30
        )
        topic_summaries = [item["text"] for item in recently_published_raw] if recently_published_raw else None
        if topic_summaries:
            logger.info(f"–¢–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å: {len(topic_summaries)} –Ω–µ–¥–∞–≤–Ω–∏—Ö —Ç–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–æ")

        # –®–ê–ì 5: –û—Ç–±–æ—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —á–µ—Ä–µ–∑ LLM (Claude/Gemini –ø–æ –∫–æ–Ω—Ñ–∏–≥—É)
        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª—é–±—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞, –Ω–µ —Ç–æ–ª—å–∫–æ marketplace-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ
        categories = await asyncio.to_thread(
            self.llm_client.select_by_categories,
            unique_messages,
            category_counts=self.all_digest_counts,
            recently_published=topic_summaries,
            category_descriptions=self.all_digest_descriptions,
        )

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∫–æ–ª—å–∫–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
        category_stats = {cat: len(posts) for cat, posts in categories.items()}
        total_count = sum(category_stats.values())

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∞—Å–∏–≤—ã–π –ª–æ–≥ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏
        stats_str = ", ".join(f"{cat}={count}" for cat, count in category_stats.items())
        logger.info(f"LLM –æ—Ç–æ–±—Ä–∞–ª: {stats_str}, –í—Å–µ–≥–æ={total_count}")

        selected_ids = {
            post["source_message_id"]
            for posts in categories.values()
            for post in posts
            if post.get("source_message_id")
        }

        if total_count == 0:
            logger.warning("Gemini –Ω–µ –æ—Ç–æ–±—Ä–∞–ª –Ω–∏ –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏")
            # Sprint 6.4: –ë–∞—Ç—á-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–º–µ—Å—Ç–æ N –≤—ã–∑–æ–≤–æ–≤
            updates = [
                {'message_id': msg["id"], 'rejection_reason': "rejected_by_llm"}
                for msg in unique_messages
            ]
            await asyncio.to_thread(self.db.mark_as_processed_batch, updates)
            return

        # –®–ê–ì 4.5 (–ù–û–í–û–ï): –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ—Å–ª–µ Gemini
        # Gemini –º–æ–∂–µ—Ç –≤—ã–±—Ä–∞—Ç—å –ø–æ—Ö–æ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö —á—É–Ω–∫–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ—á—Ç–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é
        # FIX-DUPLICATE-2: –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–π –ø–æ—Ä–æ–≥ –≤–º–µ—Å—Ç–æ —Ö–∞—Ä–¥–∫–æ–¥–∞
        all_selected_posts = [post for posts in categories.values() for post in posts]
        unique_posts, post_duplicates = await self.deduplicate_selected_posts(
            all_selected_posts, threshold=self.duplicate_threshold
        )

        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –Ω–æ–≤–æ—Å—Ç–µ–π
        if not unique_posts:
            logger.warning("–ü–æ—Å–ª–µ post-Gemini –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –Ω–æ–≤–æ—Å—Ç–µ–π")
            updates = [
                {'message_id': msg["id"], 'rejection_reason': "rejected_by_llm"}
                for msg in unique_messages
            ]
            await asyncio.to_thread(self.db.mark_as_processed_batch, updates)
            return

        # –ü–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º categories –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ—Å—Ç—ã –≤ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        unique_post_ids = {id(post) for post in unique_posts}
        filtered_categories = {}
        for cat_name, posts in categories.items():
            filtered_posts = [post for post in posts if id(post) in unique_post_ids]
            if filtered_posts:
                filtered_categories[cat_name] = filtered_posts

        categories = filtered_categories
        total_count = len(unique_posts)

        # –û–±–Ω–æ–≤–ª—è–µ–º selected_ids –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        selected_ids = {
            post["source_message_id"]
            for post in unique_posts
            if post.get("source_message_id")
        }

        logger.info(
            f"–ü–æ—Å–ª–µ post-Gemini –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {total_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π "
            f"({len(post_duplicates)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–æ)"
        )

        # –®–ê–ì 5: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ—Ä–∞—Ü–∏—è (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è + —Ç–æ–ø-N)
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–æ—Å—Ç—ã –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ –µ–¥–∏–Ω—ã–π —Å–ø–∏—Å–æ–∫
        all_posts = [post for posts in categories.values() for post in posts]

        if self.auto_moderation:
            # –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –†–ï–ñ–ò–ú: –±–µ–∑ —É—á–∞—Å—Ç–∏—è —á–µ–ª–æ–≤–µ–∫–∞
            logger.info("ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ—Ä–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞")
            moderation_result: ModerationResult = await self.auto_moderator.moderate(
                all_posts,
                top_n=self.final_top_n,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
            )
            approved_posts = moderation_result.approved_posts

            if not approved_posts:
                logger.warning("–í—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω—ã –∞–≤—Ç–æ–º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–º")
                updates = [
                    {'message_id': msg_id, 'rejection_reason': "rejected_by_auto_moderator"}
                    for msg_id in selected_ids
                ]
                await asyncio.to_thread(self.db.mark_as_processed_batch, updates)
                return

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏
            auto_rejection_reasons = moderation_result.rejection_reasons

        elif self.moderation_enabled:
            # –†–£–ß–ù–û–ô –†–ï–ñ–ò–ú: —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º –æ—Ç –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞ (legacy)
            logger.info("üë§ –†—É—á–Ω–∞—è –º–æ–¥–µ—Ä–∞—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞")
            approved_posts = await self.moderate_categories(client, categories)

            if not approved_posts:
                logger.warning("–í—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω—ã –Ω–∞ —ç—Ç–∞–ø–µ –º–æ–¥–µ—Ä–∞—Ü–∏–∏")
                updates = [
                    {'message_id': msg_id, 'rejection_reason': "rejected_by_moderator"}
                    for msg_id in selected_ids
                ]
                await asyncio.to_thread(self.db.mark_as_processed_batch, updates)
                return
            auto_rejection_reasons = {}
        else:
            # –ë–ï–ó –ú–û–î–ï–†–ê–¶–ò–ò: –±–µ—Ä–µ–º –≤—Å–µ —á—Ç–æ –µ—Å—Ç—å
            approved_posts = all_posts
            auto_rejection_reasons = {}

        approved_ids = {
            post.get("source_message_id")
            for post in approved_posts
            if post.get("source_message_id")
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º ID –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –ø–æ–º–µ—Ç–∫–∏ (—Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏)
        rejected_after_moderation = selected_ids - approved_ids
        unique_ids = {msg["id"] for msg in unique_messages}
        not_selected_ids = unique_ids - selected_ids

        # –®–ê–ì 6: –ü—É–±–ª–∏–∫–∞—Ü–∏—è
        target_channel = (
            self.all_digest_channel
            if self.all_digest_enabled and self.all_digest_channel
            else next(
                (mp.target_channel for mp in self.categories.values() if mp.target_channel),
                None,
            )
        )

        if self.auto_moderation:
            # –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –†–ï–ñ–ò–ú: —Å—Ä–∞–∑—É –ø—É–±–ª–∏–∫—É–µ–º
            logger.info(f"üì¢ –ê–≤—Ç–æ–ø—É–±–ª–∏–∫–∞—Ü–∏—è {len(approved_posts)} –Ω–æ–≤–æ—Å—Ç–µ–π –≤ {target_channel}...")

            await self.publish_digest(
                client,
                approved_posts,
                "–∫–∞—Ç–µ–≥–æ—Ä–∏–∏",
                target_channel,
                display_name="–ö–∞—Ç–µ–≥–æ—Ä–∏–∏",
            )
        else:
            # –†–£–ß–ù–û–ô –†–ï–ñ–ò–ú: —Ñ–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–π–¥–∂–µ—Å—Ç –∏ –∂–¥—ë–º —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
            digest_text = self._format_digest(approved_posts, target_channel)
            moderator_username = self.config.my_personal_account

            is_approved = await self._approve_digest(client, moderator_username, digest_text)

            if not is_approved:
                logger.warning("‚ùå –ú–æ–¥–µ—Ä–∞—Ç–æ—Ä –æ—Ç–º–µ–Ω–∏–ª –ø—É–±–ª–∏–∫–∞—Ü–∏—é –¥–∞–π–¥–∂–µ—Å—Ç–∞")
                return

            logger.info("üì¢ –ü—É–±–ª–∏–∫–∞—Ü–∏—è —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞...")

            await self.publish_digest(
                client,
                approved_posts,
                "–∫–∞—Ç–µ–≥–æ—Ä–∏–∏",
                target_channel,
                display_name="–ö–∞—Ç–µ–≥–æ—Ä–∏–∏",
            )

        # –®–ê–ì 7: –ü–æ–º–µ—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ (—Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏)

        # 7.1: –°–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –≤–æ—à–ª–∏ –≤ –ø—É–±–ª–∏–∫–∞—Ü–∏—é
        await self._mark_messages_processed(approved_posts)

        # 7.2: –°–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ—à–ª–∏ –æ—Ç–±–æ—Ä Gemini, –Ω–æ –±—ã–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω—ã –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–º
        updates = []
        for msg_id in rejected_after_moderation:
            reason = auto_rejection_reasons.get(msg_id, "rejected_by_moderator")
            updates.append({'message_id': msg_id, 'rejection_reason': reason})
        if updates:
            await asyncio.to_thread(self.db.mark_as_processed_batch, updates)

        # 7.3: –°–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ Gemini –Ω–µ –≤—ã–±—Ä–∞–ª
        updates = [
            {'message_id': msg_id, 'rejection_reason': "rejected_by_llm"}
            for msg_id in not_selected_ids
        ]
        if updates:
            await asyncio.to_thread(self.db.mark_as_processed_batch, updates)

        # 7.4: –°–æ–æ–±—â–µ–Ω–∏—è, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –∏–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã
        updates = [
            {
                'message_id': msg_id,
                'is_duplicate': (reason == "is_duplicate"),
                'rejection_reason': reason
            }
            for msg_id, reason in all_rejected.items()
        ]
        if updates:
            await asyncio.to_thread(self.db.mark_as_processed_batch, updates)

        logger.info("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

    async def _wait_for_moderation_response_retry(
        self, conv, total_posts: int, max_retries: int = 5
    ) -> list[int] | None:
        """
        –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞ (–ø–æ—Å–ª–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –≤–≤–æ–¥–∞)

        Args:
            conv: Conversation –æ–±—ä–µ–∫—Ç
            total_posts: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–æ–º–µ—Ä–æ–≤ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏–ª–∏ None –µ—Å–ª–∏ –æ—Ç–º–µ–Ω–∞
        """
        for attempt in range(max_retries):
            try:
                response = await conv.get_response(timeout=float('inf'))
                response_text = response.message.strip().lower()

                logger.info(f"üì® –ü–æ–ª—É—á–µ–Ω –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞: {response_text}")

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã –æ—Ç–º–µ–Ω—ã
                if response_text in ["–æ—Ç–º–µ–Ω–∞", "cancel"]:
                    await conv.send_message("‚ùå –ú–æ–¥–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
                    return None

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã "–æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –≤—Å–µ"
                if response_text in ["0", "–≤—Å–µ", "all"]:
                    await conv.send_message(f"‚úÖ –í—Å–µ {total_posts} –Ω–æ–≤–æ—Å—Ç–µ–π –±—É–¥—É—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω—ã")
                    return []

                # –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–º–µ—Ä–æ–≤
                excluded_ids = []
                parts = response_text.split()

                for part in parts:
                    part = part.strip(",.")
                    if part.isdigit():
                        num = int(part)
                        if 1 <= num <= total_posts:
                            excluded_ids.append(num)
                        else:
                            logger.warning(f"–ù–æ–º–µ—Ä {num} –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 1-{total_posts}")

                if not excluded_ids:
                    remaining = max_retries - attempt - 1
                    if remaining > 0:
                        await conv.send_message(
                            f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–æ–º–µ—Ä–∞. "
                            f"–û—Ç–ø—Ä–∞–≤—å –Ω–æ–º–µ—Ä–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1 2 3 5 6). "
                            f"–û—Å—Ç–∞–ª–æ—Å—å –ø–æ–ø—ã—Ç–æ–∫: {remaining}"
                        )
                        continue
                    else:
                        await conv.send_message(
                            "‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫. –ú–æ–¥–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞."
                        )
                        return None

                await conv.send_message(
                    f"‚úÖ –ò—Å–∫–ª—é—á–µ–Ω–æ {len(excluded_ids)} –Ω–æ–≤–æ—Å—Ç–µ–π: {', '.join(map(str, excluded_ids))}\n"
                    f"–ë—É–¥–µ—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {total_posts - len(excluded_ids)} –Ω–æ–≤–æ—Å—Ç–µ–π"
                )
                return excluded_ids

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –æ–∂–∏–¥–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}", exc_info=True)
                return None

        return None

    async def _wait_for_moderation_response(
        self, client: TelegramClient, personal_account: str, message: str, total_posts: int
    ) -> list[int] | None:
        """
        –û–∂–∏–¥–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞ —á–µ—Ä–µ–∑ polling

        Args:
            client: Telegram –∫–ª–∏–µ–Ω—Ç
            personal_account: Username –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏
            total_posts: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π

        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–æ–º–µ—Ä–æ–≤ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏–ª–∏ None –µ—Å–ª–∏ –æ—Ç–º–µ–Ω–∞
        """
        from datetime import datetime, timedelta, timezone

        logger.info("‚è≥ –û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é –∏ –æ–∂–∏–¥–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞...")

        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –º–æ–¥–µ—Ä–∞—Ü–∏–∏
            sent_message = await client.send_message(personal_account, message)
            sent_time = datetime.now(timezone.utc)
            logger.info(f"‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä—É {personal_account}")

            # –ñ–¥–µ–º –æ—Ç–≤–µ—Ç–∞ —Å —Ç–∞–π–º–∞—É—Ç–æ–º (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
            timeout_seconds = self.moderation_timeout_hours * 3600
            logger.info(f"‚è∞ –û–∂–∏–¥–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞ (timeout: {self.moderation_timeout_hours}—á)")

            check_interval = 3  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã
            elapsed = 0

            while elapsed < timeout_seconds:
                await asyncio.sleep(check_interval)
                elapsed += check_interval

                # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞
                messages = await client.get_messages(personal_account, limit=10)

                # –ò—â–µ–º –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
                for msg in messages:
                    if msg.date > sent_time and msg.out == False:  # –í—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ—Å–ª–µ –Ω–∞—à–µ–≥–æ
                        response_text = msg.text.strip().lower() if msg.text else ""

                        if not response_text:
                            continue

                        logger.info(f"üì® –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞: {response_text}")

                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã –æ—Ç–º–µ–Ω—ã
                        if response_text in ["–æ—Ç–º–µ–Ω–∞", "cancel"]:
                            await client.send_message(personal_account, "‚ùå –ú–æ–¥–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
                            return None

                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã "–æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –≤—Å–µ"
                        if response_text in ["0", "–≤—Å–µ", "all"]:
                            await client.send_message(
                                personal_account,
                                f"‚úÖ –í—Å–µ {total_posts} –Ω–æ–≤–æ—Å—Ç–µ–π –±—É–¥—É—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω—ã"
                            )
                            return []

                        # –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–º–µ—Ä–æ–≤
                        excluded_ids = []
                        parts = response_text.split()

                        for part in parts:
                            # –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã —Ç–∏–ø–∞ –∑–∞–ø—è—Ç—ã—Ö
                            part = part.strip(",.")
                            if part.isdigit():
                                num = int(part)
                                if 1 <= num <= total_posts:
                                    excluded_ids.append(num)
                                else:
                                    logger.warning(f"–ù–æ–º–µ—Ä {num} –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 1-{total_posts}")

                        if not excluded_ids:
                            await client.send_message(
                                personal_account,
                                "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–æ–º–µ—Ä–∞. "
                                "–û—Ç–ø—Ä–∞–≤—å –Ω–æ–º–µ—Ä–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä: 1 2 3 5 6)"
                            )
                            continue  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∂–¥–∞—Ç—å

                        await client.send_message(
                            personal_account,
                            f"‚úÖ –ò—Å–∫–ª—é—á–µ–Ω–æ {len(excluded_ids)} –Ω–æ–≤–æ—Å—Ç–µ–π: {', '.join(map(str, excluded_ids))}\n"
                            f"–ë—É–¥–µ—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ: {total_posts - len(excluded_ids)} –Ω–æ–≤–æ—Å—Ç–µ–π"
                        )
                        return excluded_ids

            # Timeout –º–æ–¥–µ—Ä–∞—Ü–∏–∏ - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—É–±–ª–∏–∫—É–µ–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏
            logger.warning(
                f"‚è∞ Timeout –º–æ–¥–µ—Ä–∞—Ü–∏–∏ ({self.moderation_timeout_hours}—á) - "
                f"–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è –≤—Å–µ—Ö {total_posts} –Ω–æ–≤–æ—Å—Ç–µ–π"
            )
            try:
                await client.send_message(
                    personal_account,
                    f"‚è∞ –í—Ä–µ–º—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏ –∏—Å—Ç–µ–∫–ª–æ ({self.moderation_timeout_hours}—á)\n"
                    f"‚úÖ –í—Å–µ {total_posts} –Ω–æ–≤–æ—Å—Ç–µ–π –±—É–¥—É—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"
                )
            except Exception:
                pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
            return []  # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ = –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –≤—Å–µ

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–∂–∏–¥–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞: {e}", exc_info=True)
            return None

    def _format_digest(self, approved_posts: list[dict], target_channel: str) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏

        Args:
            approved_posts: –°–ø–∏—Å–æ–∫ –æ–¥–æ–±—Ä–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
            target_channel: –ö–∞–Ω–∞–ª –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏

        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–∞–π–¥–∂–µ—Å—Ç–∞
        """
        from datetime import timedelta
        from utils.timezone import now_msk

        yesterday = now_msk() - timedelta(days=1)
        date_str = yesterday.strftime("%d-%m-%Y")
        header = self.publication_header_template.format(
            date=date_str,
            display_name="–ö–∞—Ç–µ–≥–æ—Ä–∏–∏",
            marketplace="–∫–∞—Ç–µ–≥–æ—Ä–∏–∏",
            channel=target_channel,
            profile=getattr(self.config, "profile", "")
        )

        digest_parts = [header, ""]

        for idx, post in enumerate(approved_posts, 1):
            title = post.get("title", "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞")
            description = post.get("description", "")
            source_link = post.get("source_link", "")

            digest_parts.append(f"{idx}. **{title}**")
            digest_parts.append(f"{description}")
            if source_link:
                digest_parts.append(source_link)
            digest_parts.append("")

        digest_parts.append(self.publication_footer_template)
        digest_text = "\n".join(digest_parts)

        return digest_text

    async def _approve_digest(
        self, client: TelegramClient, personal_account: str, digest_text: str
    ) -> bool:
        """
        –í—Ç–æ—Ä–∞—è —Å—Ç–∞–¥–∏—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏: —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –ø–µ—Ä–µ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–µ–π

        Args:
            client: Telegram –∫–ª–∏–µ–Ω—Ç
            personal_account: Username –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞
            digest_text: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–∞–π–¥–∂–µ—Å—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –¥–ª–∏–Ω—ã)

        Returns:
            True –µ—Å–ª–∏ –æ–¥–æ–±—Ä–µ–Ω–æ, False –µ—Å–ª–∏ –æ—Ç–º–µ–Ω–µ–Ω–æ
        """
        from datetime import datetime, timedelta, timezone

        logger.info("üìã –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –Ω–∞ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ...")

        try:
            # –°–ª—É–∂–µ–±–Ω—ã–µ —á–∞—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
            header = (
                "**üì¢ –£–¢–í–ï–†–ñ–î–ï–ù–ò–ï –î–ê–ô–î–ñ–ï–°–¢–ê**\n\n"
                f"üìä –ì–æ—Ç–æ–≤ –¥–∞–π–¥–∂–µ—Å—Ç –∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π\n"
                f"üìè –†–∞–∑–º–µ—Ä: {len(digest_text)} —Å–∏–º–≤–æ–ª–æ–≤\n\n"
                + "=" * 50 + "\n\n"
            )

            footer = (
                "\n\n" + "=" * 50 + "\n\n"
                "–û—Ç–ø—Ä–∞–≤—å –∫–æ–º–∞–Ω–¥—É –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏:\n"
                "‚Ä¢ `–æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å` / `ok` / `–¥–∞` - –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å\n"
                "‚Ä¢ `–æ—Ç–º–µ–Ω–∞` - –æ—Ç–º–µ–Ω–∏—Ç—å –ø—É–±–ª–∏–∫–∞—Ü–∏—é\n"
            )

            # –í—ã—á–∏—Å–ª—è–µ–º —Å–∫–æ–ª—å–∫–æ —Å–∏–º–≤–æ–ª–æ–≤ –¥–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è preview –¥–∞–π–¥–∂–µ—Å—Ç–∞
            available_length = (
                self.TELEGRAM_MESSAGE_LIMIT - len(header) - len(footer) - self.PREVIEW_SAFETY_MARGIN
            )

            # –§–æ—Ä–º–∏—Ä—É–µ–º preview –¥–∞–π–¥–∂–µ—Å—Ç–∞
            if len(digest_text) <= available_length:
                digest_preview = digest_text
            else:
                digest_preview = digest_text[:available_length] + "\n\n... (–æ–±—Ä–µ–∑–∞–Ω–æ –¥–ª—è –ø—Ä–µ–≤—å—é)"

            # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            approval_message = header + digest_preview + footer

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–π–¥–∂–µ—Å—Ç –Ω–∞ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
            sent_message = await client.send_message(personal_account, approval_message)
            sent_time = datetime.now(timezone.utc)
            logger.info(f"‚úÖ –î–∞–π–¥–∂–µ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä—É {personal_account}")

            # –ñ–¥–µ–º –æ—Ç–≤–µ—Ç–∞ —Å —Ç–∞–π–º–∞—É—Ç–æ–º 1 —á–∞—Å
            timeout_seconds = 3600  # 1 —á–∞—Å
            logger.info(f"‚è∞ –û–∂–∏–¥–∞–Ω–∏–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞ (timeout: 1—á)")

            check_interval = 3  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã
            elapsed = 0

            while elapsed < timeout_seconds:
                await asyncio.sleep(check_interval)
                elapsed += check_interval

                # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞
                messages = await client.get_messages(personal_account, limit=10)

                # –ò—â–µ–º –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
                for msg in messages:
                    if msg.date > sent_time and msg.out == False:  # –í—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                        response_text = msg.text.strip().lower() if msg.text else ""

                        if not response_text:
                            continue

                        logger.info(f"üì® –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–∞: {response_text}")

                        # –ö–æ–º–∞–Ω–¥–∞ –æ—Ç–º–µ–Ω—ã
                        if response_text in ["–æ—Ç–º–µ–Ω–∞", "cancel"]:
                            await client.send_message(personal_account, "‚ùå –ü—É–±–ª–∏–∫–∞—Ü–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
                            logger.info("‚ùå –ú–æ–¥–µ—Ä–∞—Ç–æ—Ä –æ—Ç–º–µ–Ω–∏–ª –ø—É–±–ª–∏–∫–∞—Ü–∏—é")
                            return False

                        # –ö–æ–º–∞–Ω–¥—ã —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
                        if response_text in ["–æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å", "ok", "–¥–∞", "yes"]:
                            await client.send_message(personal_account, "‚úÖ –î–∞–π–¥–∂–µ—Å—Ç —É—Ç–≤–µ—Ä–∂–¥–µ–Ω, –ø—É–±–ª–∏–∫—É–µ–º...")
                            logger.info("‚úÖ –ú–æ–¥–µ—Ä–∞—Ç–æ—Ä —É—Ç–≤–µ—Ä–¥–∏–ª –ø—É–±–ª–∏–∫–∞—Ü–∏—é")
                            return True

                        # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞
                        await client.send_message(
                            personal_account,
                            "‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π:\n"
                            "‚Ä¢ `–æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å` / `ok` / `–¥–∞` - –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å\n"
                            "‚Ä¢ `–æ—Ç–º–µ–Ω–∞` - –æ—Ç–º–µ–Ω–∏—Ç—å"
                        )
                        continue

            # Timeout - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Ç–≤–µ—Ä–∂–¥–∞–µ–º
            logger.warning("‚è∞ Timeout —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è (1—á) - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è")
            try:
                await client.send_message(
                    personal_account,
                    "‚è∞ –í—Ä–µ–º—è —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∏—Å—Ç–µ–∫–ª–æ (1—á)\n"
                    "‚úÖ –î–∞–π–¥–∂–µ—Å—Ç –±—É–¥–µ—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"
                )
            except Exception:
                pass
            return True  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Ç–≤–µ—Ä–∂–¥–∞–µ–º –ø—Ä–∏ timeout

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞: {e}", exc_info=True)
            return False

    async def _mark_messages_processed(self, approved_posts: list[dict]) -> None:
        """
        –ü–æ–º–µ—á–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –æ–¥–æ–±—Ä–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –≤ –ë–î

        Args:
            approved_posts: –°–ø–∏—Å–æ–∫ –æ–¥–æ–±—Ä–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ —Å source_message_id
        """
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –±–∞—Ç—á-–∞–ø–¥–µ–π—Ç—ã –¥–ª—è –ë–î
            updates = [
                {
                    'message_id': post.get("source_message_id"),
                    'gemini_score': post.get("score")
                }
                for post in approved_posts
                if post.get("source_message_id")
            ]

            if updates:
                await asyncio.to_thread(self.db.mark_as_processed_batch, updates)
                logger.info(f"‚úÖ –ü–æ–º–µ—á–µ–Ω–æ {len(updates)} —Å–æ–æ–±—â–µ–Ω–∏–π –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ")
            else:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø–æ–º–µ—Ç–∫–∏ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–º–µ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ: {e}", exc_info=True)

    async def moderate_categories(
        self, client: TelegramClient, categories: dict[str, list[dict]]
    ) -> list[dict]:
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ—Ä–∞—Ü–∏—è: –∏—Å–∫–ª—é—á–µ–Ω–∏–µ 5 –∏–∑ 15 –Ω–æ–≤–æ—Å—Ç–µ–π (–ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º)"""

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ 3 –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        all_posts = []

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∫ –∫–∞–∂–¥–æ–º—É –ø–æ—Å—Ç—É
        for cat_name, posts in categories.items():
            for post in posts:
                post["category"] = cat_name
                all_posts.append(post)

        # –í–ê–ñ–ù–û: –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score –ü–ï–†–ï–î –ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ–º moderation_id
        # —á—Ç–æ–±—ã –Ω–æ–º–µ—Ä–∞ —Å–æ–≤–ø–∞–¥–∞–ª–∏ —Å —Ç–µ–º, —á—Ç–æ –≤–∏–¥–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –º–æ–¥–µ—Ä–∞—Ü–∏–∏
        all_posts.sort(key=lambda x: x.get('score', 0), reverse=True)

        total = len(all_posts)
        exclude_goal = max(0, min(self.processor_exclude_count, total))
        logger.info(
            "üìã –û—Ç–ø—Ä–∞–≤–∫–∞ %s –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é (–Ω—É–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å %s)",
            total,
            exclude_goal,
        )

        # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º ID –¥–ª—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏ –ü–û–°–õ–ï —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
        for idx, post in enumerate(all_posts, 1):
            post["moderation_id"] = idx

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏ (–ø–µ—Ä–µ–¥–∞–µ–º –£–ñ–ï –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)
        message = self._format_categories_moderation_message(all_posts, exclude_goal)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –ª–∏—á–∫—É –∏ –∂–¥–µ–º –æ—Ç–≤–µ—Ç–∞
        personal_account = self.config.my_personal_account
        excluded_ids = await self._wait_for_moderation_response(
            client, personal_account, message, total
        )

        if excluded_ids is None:
            # –ú–æ–¥–µ—Ä–∞—Ç–æ—Ä –æ—Ç–º–µ–Ω–∏–ª –º–æ–¥–µ—Ä–∞—Ü–∏—é
            logger.warning("–ú–æ–¥–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä–æ–º")
            return []

        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ—Å—Ç—ã - –∏—Å–∫–ª—é—á–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –Ω–æ–º–µ—Ä–∞
        approved_posts = [post for post in all_posts if post["moderation_id"] not in excluded_ids]

        logger.info(
            f"‚úÖ –ú–æ–¥–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: –∏—Å–∫–ª—é—á–µ–Ω–æ {len(excluded_ids)}, –æ–¥–æ–±—Ä–µ–Ω–æ {len(approved_posts)}"
        )
        return approved_posts

    def _format_categories_moderation_message(
        self, all_posts: list[dict], exclude_goal: int
    ) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏ 3-–∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã

        Args:
            all_posts: –£–ñ–ï –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –ø—Ä–∏—Å–≤–æ–µ–Ω–Ω—ã–º–∏ moderation_id
            exclude_goal: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
        """

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –£–ñ–ï –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ (–Ω–µ –ø–µ—Ä–µ—Å–æ—Ä—Ç–∏—Ä–æ–≤—ã–≤–∞–µ–º!)

        lines = ["üìã **–ú–û–î–ï–†–ê–¶–ò–Ø: –¢–û–ü–û–í–´–ï –ù–û–í–û–°–¢–ò**"]
        if exclude_goal > 0:
            lines.append(
                f"_–ù—É–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å {exclude_goal} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {len(all_posts)}_\n"
            )
        else:
            lines.append("_–ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏, –æ—Ç–ø—Ä–∞–≤–∏–≤ –∏—Ö –Ω–æ–º–µ—Ä–∞_\n")

        # –í—ã–≤–æ–¥–∏–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –µ–¥–∏–Ω—ã–º —Å–ø–∏—Å–∫–æ–º (–£–ñ–ï –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ score)
        for post in all_posts:
            mod_id = post.get('moderation_id', 0)
            emoji = NUMBER_EMOJIS.get(mod_id, f"{mod_id}.")
            category_tag = post.get('category', '').upper()
            lines.append(f"{emoji} **{post['title']}**")
            lines.append(f"_{post['description'][:100]}..._")
            lines.append(f"‚≠ê {post.get('score', 0)}/10 | üì¶ {category_tag}\n")

        lines.append("=" * 50)
        lines.append(f"üìä **–í—Å–µ–≥–æ:** {len(all_posts)} –Ω–æ–≤–æ—Å—Ç–µ–π\n")
        lines.append("**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:**")
        if exclude_goal > 0:
            lines.append(
                f"–û—Ç–ø—Ä–∞–≤—å –Ω–æ–º–µ—Ä–∞ –∫–æ—Ç–æ—Ä—ã–µ **–ò–°–ö–õ–Æ–ß–ò–¢–¨ –∏–∑ –ü–£–ë–õ–ò–ö–ê–¶–ò–ò** —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª ({exclude_goal} —à—Ç.)"
            )
            sample = " ".join(str(i) for i in range(1, min(exclude_goal, 5) + 1))
            lines.append(f"–ù–∞–ø—Ä–∏–º–µ—Ä: `{sample}`\n")
        else:
            lines.append("–ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ—Ç–ø—Ä–∞–≤—å –Ω–æ–º–µ—Ä–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å –∏–∑ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏\n")
        lines.append("–ò–ª–∏ –æ—Ç–ø—Ä–∞–≤—å `0` –∏–ª–∏ `–≤—Å–µ` —á—Ç–æ–±—ã –æ–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏")
        lines.append("–ò–ª–∏ –æ—Ç–ø—Ä–∞–≤—å `–æ—Ç–º–µ–Ω–∞` —á—Ç–æ–±—ã –æ—Ç–º–µ–Ω–∏—Ç—å –º–æ–¥–µ—Ä–∞—Ü–∏—é")

        return "\n".join(lines)

    def _format_moderation_message(self, posts: list[dict], marketplace: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏"""
        lines = [f"üìã **–ú–û–î–ï–†–ê–¶–ò–Ø: {marketplace.upper()}**"]
        lines.append("_(–û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏)_\n")

        for post in posts:
            idx = post["moderation_id"]
            emoji = NUMBER_EMOJIS.get(idx, f"{idx}Ô∏è‚É£")

            lines.append(f"{emoji} **{post['title']}**")
            lines.append(f"_{post['description'][:150]}..._")
            lines.append(f"‚≠ê –û—Ü–µ–Ω–∫–∞: {post.get('score', 0)}/10\n")

        lines.append("=" * 50)
        lines.append(f"üìä **–í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π:** {len(posts)}\n")
        lines.append("**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:**")
        lines.append("–û—Ç–ø—Ä–∞–≤—å –Ω–æ–º–µ—Ä–∞ –¥–ª—è –£–î–ê–õ–ï–ù–ò–Ø —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª")
        lines.append("–ù–∞–ø—Ä–∏–º–µ—Ä: `1 3 5` - —É–¥–∞–ª–∏—Ç –Ω–æ–≤–æ—Å—Ç–∏ 1, 3 –∏ 5\n")
        lines.append("–û—Ç–ø—Ä–∞–≤—å `0` –∏–ª–∏ `–≤—Å–µ` —á—Ç–æ–±—ã –æ–¥–æ–±—Ä–∏—Ç—å –í–°–ï –Ω–æ–≤–æ—Å—Ç–∏")

        return "\n".join(lines)

    @staticmethod
    @staticmethod
    def _split_text_by_limit(text: str, limit: int) -> list[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–∞–π–¥–∂–µ—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏ –Ω–µ –¥–ª–∏–Ω–Ω–µ–µ limit —Å–∏–º–≤–æ–ª–æ–≤.

        –ê–ª–≥–æ—Ä–∏—Ç–º:
        - –†–µ–∂–µ–º –ø–æ –∞–±–∑–∞—Ü–∞–º (–¥–≤–æ–π–Ω–æ–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏) ‚Äî –Ω–µ —Ä–≤—ë–º –Ω–æ–≤–æ—Å—Ç—å –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ
        - –ï—Å–ª–∏ –æ–¥–∏–Ω –∞–±–∑–∞—Ü —Å–∞–º –ø–æ —Å–µ–±–µ > limit ‚Äî —Ä–µ–∂–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º
        - –î–æ–±–∞–≤–ª—è–µ—Ç –º–µ—Ç–∫—É ¬´—á–∞—Å—Ç—å N/M¬ª –≤ –∫–æ–Ω–µ—Ü –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏ (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –µ—Å–ª–∏ –æ–¥–Ω–∞)

        Returns:
            –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫-—Å–æ–æ–±—â–µ–Ω–∏–π, –∫–∞–∂–¥–æ–µ <= limit —Å–∏–º–≤–æ–ª–æ–≤.
        """
        SUFFIX_RESERVE = 20  # ¬´\n\nüìÑ –ß–∞—Å—Ç—å 1/9¬ª ‚Äî –∑–∞–ø–∞—Å –ø–æ–¥ –º–µ—Ç–∫—É
        effective_limit = limit - SUFFIX_RESERVE

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã (–±–ª–æ–∫–∏ –º–µ–∂–¥—É –ø—É—Å—Ç—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏)
        paragraphs = text.split("\n\n")

        parts: list[str] = []
        current_chunks: list[str] = []
        current_len = 0

        for para in paragraphs:
            para_len = len(para) + 2  # +2 –∑–∞ \n\n

            # –ê–±–∑–∞—Ü —Å–∞–º –ø–æ —Å–µ–±–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ‚Äî —Ä–µ–∂–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º
            if para_len > effective_limit:
                # –°–Ω–∞—á–∞–ª–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ
                if current_chunks:
                    parts.append("\n\n".join(current_chunks))
                    current_chunks = []
                    current_len = 0
                # –†–µ–∂–µ–º –∞–±–∑–∞—Ü –ø–æ —Å—Ç—Ä–æ–∫–∞–º
                for line in para.split("\n"):
                    line_len = len(line) + 1
                    if current_len + line_len > effective_limit and current_chunks:
                        parts.append("\n\n".join(current_chunks))
                        current_chunks = [line]
                        current_len = line_len
                    else:
                        current_chunks.append(line)
                        current_len += line_len
                continue

            if current_len + para_len > effective_limit and current_chunks:
                # –ù–µ –≤–ª–µ–∑–∞–µ—Ç ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —á–∞—Å—Ç—å
                parts.append("\n\n".join(current_chunks))
                current_chunks = [para]
                current_len = para_len
            else:
                current_chunks.append(para)
                current_len += para_len

        if current_chunks:
            parts.append("\n\n".join(current_chunks))

        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫—É ¬´—á–∞—Å—Ç—å N/M¬ª –µ—Å–ª–∏ —á–∞—Å—Ç–µ–π –±–æ–ª—å—à–µ –æ–¥–Ω–æ–π
        if len(parts) > 1:
            total = len(parts)
            parts = [f"{p}\n\nüìÑ –ß–∞—Å—Ç—å {i}/{total}" for i, p in enumerate(parts, 1)]

        return parts

    @staticmethod
    def _split_digest_by_limit(lines: list[str], limit: int) -> list[str]:
        """–£—Å—Ç–∞—Ä–µ–≤—à–∏–π –º–µ—Ç–æ–¥ ‚Äî –¥–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ _split_text_by_limit."""
        return NewsProcessor._split_text_by_limit("\n".join(lines), limit)

    @staticmethod
    def _ensure_post_fields(post: dict) -> dict:
        """QA-1: Fallback-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ—Å—Ç–æ–≤ –±–µ–∑ title/description.

        –î–µ–ª–µ–≥–∏—Ä—É–µ—Ç –≤ utils.formatters.ensure_post_fields.
        """
        return ensure_post_fields(post)

    async def publish_digest(
        self,
        client: TelegramClient,
        posts: list[dict],
        marketplace: str,
        target_channel: str,
        display_name: str | None = None,
    ):
        """–ü—É–±–ª–∏–∫–∞—Ü–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞ –≤ –∫–∞–Ω–∞–ª"""

        logger.info(f"üì§ –ü—É–±–ª–∏–∫–∞—Ü–∏—è {len(posts)} –Ω–æ–≤–æ—Å—Ç–µ–π –≤ {target_channel}")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–π–¥–∂–µ—Å—Ç
        yesterday = now_msk() - timedelta(days=1)
        date_str = yesterday.strftime("%d-%m-%Y")
        header_name = display_name or marketplace

        context = {
            "date": date_str,
            "display_name": header_name,
            "marketplace": marketplace,
            "channel": target_channel,
            "profile": getattr(self.config, "profile", ""),
        }

        try:
            header_line = self.publication_header_template.format(**context)
        except Exception as exc:  # noqa: BLE001
            logger.warning(
                "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥—Å—Ç–∞–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ publication.header_template: %s", exc
            )
            header_line = f"üìå –ì–ª–∞–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ {header_name} –∑–∞ {date_str}"

        # –í—ã—á–∏—Å–ª—è–µ–º footer
        footer = self.publication_footer_template.strip()
        footer_text = ""
        if footer:
            try:
                footer_text = footer.format(**context)
            except Exception as exc:  # noqa: BLE001
                logger.warning(
                    "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥—Å—Ç–∞–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ publication.footer_template: %s", exc
                )
                footer_text = footer

        # –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç —á–µ—Ä–µ–∑ LLM (–≤—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥ Claude)
        # –ï—Å–ª–∏ LLM-–¥–∞–π–¥–∂–µ—Å—Ç –Ω–µ –≤–ª–µ–∑–∞–µ—Ç ‚Äî –æ–±—Ä–µ–∑–∞–µ–º –ø–æ—Å—Ç—ã –∏ –ø–æ–≤—Ç–æ—Ä—è–µ–º
        digest = ""
        active_posts = list(posts)

        while True:
            if not active_posts:
                digest = header_line.strip() + "\n\n" + footer_text
                logger.warning("‚ö†Ô∏è –í—Å–µ –ø–æ—Å—Ç—ã –æ–±—Ä–µ–∑–∞–Ω—ã ‚Äî –ø—É–±–ª–∏–∫—É–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫")
                break

            try:
                rewritten = await asyncio.to_thread(
                    self.llm_client.rewrite_digest,
                    active_posts,
                    header_line.strip(),
                    footer_text,
                )
                if rewritten:
                    digest = rewritten
                    logger.info("‚úçÔ∏è –î–∞–π–¥–∂–µ—Å—Ç –ø–µ—Ä–µ–ø–∏—Å–∞–Ω —á–µ—Ä–µ–∑ LLM (%d —Å–∏–º–≤–æ–ª–æ–≤, %d –Ω–æ–≤–æ—Å—Ç–µ–π)",
                                len(digest), len(active_posts))
            except Exception as exc:  # noqa: BLE001
                logger.warning("LLM rewrite_digest –Ω–µ —É–¥–∞–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º —à–∞–±–ª–æ–Ω: %s", exc)

            # Fallback: —à–∞–±–ª–æ–Ω–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            if not digest:
                lines = [header_line.strip() + "\n"]
                for idx, post in enumerate(active_posts, 1):
                    post = self._ensure_post_fields(post)
                    emoji = NUMBER_EMOJIS.get(idx, f"{idx}" + "\ufe0f\u20e3")
                    lines.append(f"{emoji} **{post['title']}**\n")
                    lines.append(f"{post['description']}\n")
                    if post.get("source_link"):
                        lines.append(f"{post['source_link']}\n")
                if footer_text:
                    lines.append(footer_text)
                digest = "\n".join(lines)

            # –í–ª–µ–∑–∞–µ—Ç ‚Äî –≤—ã—Ö–æ–¥–∏–º
            if len(digest) <= self.TELEGRAM_MESSAGE_LIMIT:
                break

            # –ù–µ –≤–ª–µ–∑–∞–µ—Ç ‚Äî —É–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–æ–≤–æ—Å—Ç—å –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
            dropped = active_posts.pop()
            logger.warning(
                "‚ö†Ô∏è –î–∞–π–¥–∂–µ—Å—Ç %d —Å–∏–º–≤ > %d –ª–∏–º–∏—Ç. –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–æ–≤–æ—Å—Ç—å ('%s'), –æ—Å—Ç–∞–ª–æ—Å—å %d.",
                len(digest), self.TELEGRAM_MESSAGE_LIMIT,
                dropped.get("title", "?")[:50], len(active_posts),
            )
            digest = ""  # —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏

        digest_parts = [digest]

        # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞
        async def resolve_entity(channel: str, max_wait: int = 600):
            """–†–µ–∑–æ–ª–≤–∏—Ç entity –∫–∞–Ω–∞–ª–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π FloodWait.
            –ñ–¥—ë—Ç –µ—Å–ª–∏ FloodWait <= max_wait, –∏–Ω–∞—á–µ –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ."""
            while True:
                try:
                    return await client.get_entity(channel)
                except FloodWaitError as e:
                    if e.seconds > max_wait:
                        logger.error(
                            "‚ùå FloodWait %ds –ø—Ä–∏ —Ä–µ–∑–æ–ª–≤–µ %s –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç %ds ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º",
                            e.seconds, channel, max_wait,
                        )
                        raise
                    logger.warning(
                        "‚è≥ FloodWait %ds –ø—Ä–∏ —Ä–µ–∑–æ–ª–≤–µ %s ‚Äî –∂–¥—ë–º...", e.seconds, channel
                    )
                    await asyncio.sleep(e.seconds + 1)

        preview_channel = (self.publication_preview_channel or "").strip()
        if preview_channel:
            try:
                # Security: Rate limiting –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç Telegram API ban
                # –ü–æ–ª—É—á–∞–µ–º ID –∫–∞–Ω–∞–ª–∞ –¥–ª—è per-chat limiting
                preview_entity = await resolve_entity(preview_channel)
                for part in digest_parts:
                    await self._rate_limiter.acquire(
                        chat_id=preview_entity.id,
                        endpoint="send_message",
                        priority=1  # Preview –∏–º–µ–µ—Ç —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
                    )
                    await client.send_message(preview_channel, part)
                logger.info("üìÑ –ß–µ—Ä–Ω–æ–≤–∏–∫ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ %s", preview_channel)
            except Exception as exc:  # noqa: BLE001
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–µ–≤—å—é –≤ %s: %s", preview_channel, exc)

        # –ü—É–±–ª–∏–∫—É–µ–º –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞–Ω–∞–ª
        target_entity = await resolve_entity(target_channel)
        for part in digest_parts:
            await self._rate_limiter.acquire(
                chat_id=target_entity.id,
                endpoint="send_message",
                priority=2  # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∏–º–µ–µ—Ç –≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            )
            await client.send_message(target_channel, part)
        logger.info(f"‚úÖ –î–∞–π–¥–∂–µ—Å—Ç –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω –≤ {target_channel}")

        notify_account = (self.publication_notify_account or "").strip()
        if notify_account:
            try:
                notify_entity = await resolve_entity(notify_account)
                await self._rate_limiter.acquire(
                    chat_id=notify_entity.id,
                    endpoint="send_message",
                    priority=0  # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∏–º–µ–µ—Ç –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
                )
                await client.send_message(
                    notify_account,
                    f"‚úÖ –î–∞–π–¥–∂–µ—Å—Ç –Ω–∞ {context['date']} –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω –≤ {target_channel}",
                )
            except Exception as exc:  # noqa: BLE001
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ %s: %s", notify_account, exc)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º embeddings (CR-C5: batch encoding)
        texts = [post["text"] for post in posts]
        embeddings_array = await self.embeddings.encode_batch_async(texts, batch_size=32)
        logger.debug(f"CR-C5: Batch encoded {len(texts)} posts for saving")

        post_ids = []
        # Sprint 6.3: –ù–µ–±–ª–æ–∫–∏—Ä—É—é—â–∏–π –¥–æ—Å—Ç—É–ø –∫ –ë–î
        for post, embedding in zip(posts, embeddings_array):
            try:
                await asyncio.to_thread(
                    self.db.save_published,
                    text=post["text"],
                    embedding=embedding,
                    source_message_id=post["source_message_id"],
                    source_channel_id=post["source_channel_id"],
                )
                post_ids.append(post["source_message_id"])
            except Exception as e:
                logger.error(
                    f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Å—Ç–∞ {post.get('source_message_id')}: {e}",
                    exc_info=True,
                )

        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(posts)} embeddings –≤ –ë–î")

        # QA-2: –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à –ø–æ—Å–ª–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö
        self._update_published_cache(post_ids, list(embeddings_array))

    async def run(self):
        """–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ 3-–∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—É—é —Å–∏—Å—Ç–µ–º—É"""

        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Telegram —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º safe_connect –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è FloodWait –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
        session_name = self.config.get("telegram.session_name")
        client = TelegramClient(
            session_name, self.config.telegram_api_id, self.config.telegram_api_hash
        )

        await safe_connect(client, session_name)

        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ 3-–∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—É—é —Å–∏—Å—Ç–µ–º—É
            await self.process_all_categories(client)
        finally:
            await client.disconnect()
            self.db.close()

    def __del__(self):
        """Cleanup on garbage collection"""
        try:
            self.db.close()
        except Exception:
            pass  # Suppress errors during cleanup
