"""
–ú–æ–¥—É–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –º–æ–¥–µ—Ä–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π.

–ó–∞–º–µ–Ω—è–µ—Ç —Ä—É—á–Ω—É—é –º–æ–¥–µ—Ä–∞—Ü–∏—é –Ω–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å:
1. –§–∏–Ω–∞–ª—å–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
2. –û—Ç–±–æ—Ä —Ç–æ–ø-N –ø–æ score
3. –ü—É–±–ª–∏–∫–∞—Ü–∏—è –±–µ–∑ —É—á–∞—Å—Ç–∏—è —á–µ–ª–æ–≤–µ–∫–∞
"""

import asyncio
from dataclasses import dataclass

import numpy as np

from services.embeddings import EmbeddingService
from utils.logger import get_logger

logger = get_logger(__name__)


@dataclass
class ModerationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –º–æ–¥–µ—Ä–∞—Ü–∏–∏"""
    approved_posts: list[dict]
    rejected_posts: list[dict]
    rejection_reasons: dict[int, str]  # source_message_id -> reason


class AutoModerator:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –º–æ–¥–µ—Ä–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π.

    –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –ø–µ—Ä–µ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–µ–π:
    - –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ embeddings
    - –û—Ç–±–æ—Ä —Ç–æ–ø-N –ø–æ score
    - –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
    """

    def __init__(
        self,
        embeddings_service: EmbeddingService,
        *,
        duplicate_threshold: float = 0.85,
        final_top_n: int = 10,
    ):
        """
        Args:
            embeddings_service: –°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å embeddings
            duplicate_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (0.85 = –ø–æ—á—Ç–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ)
            final_top_n: –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –¥–∞–π–¥–∂–µ—Å—Ç–µ
        """
        self.embeddings = embeddings_service
        self.duplicate_threshold = duplicate_threshold
        self.final_top_n = final_top_n

    async def moderate(
        self,
        posts: list[dict],
        *,
        top_n: int | None = None,
    ) -> ModerationResult:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ—Ä–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π.

        Args:
            posts: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –æ—Ç Gemini —Å –ø–æ–ª—è–º–∏:
                   {title, description, score, source_message_id, text, ...}
            top_n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é self.final_top_n)

        Returns:
            ModerationResult —Å –æ–¥–æ–±—Ä–µ–Ω–Ω—ã–º–∏ –∏ –æ—Ç–∫–ª–æ–Ω—ë–Ω–Ω—ã–º–∏ –Ω–æ–≤–æ—Å—Ç—è–º–∏
        """
        target_count = top_n or self.final_top_n
        rejection_reasons: dict[int, str] = {}

        if not posts:
            logger.warning("AutoModerator: –ø–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π")
            return ModerationResult(
                approved_posts=[],
                rejected_posts=[],
                rejection_reasons={},
            )

        logger.info(f"ü§ñ AutoModerator: –Ω–∞—á–∏–Ω–∞—é –º–æ–¥–µ—Ä–∞—Ü–∏—é {len(posts)} –Ω–æ–≤–æ—Å—Ç–µ–π (—Ü–µ–ª—å: {target_count})")

        # –®–ê–ì 1: –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        valid_posts = []
        for post in posts:
            post_id = post.get("source_message_id", id(post))

            if not post.get("title"):
                rejection_reasons[post_id] = "missing_title"
                logger.debug(f"–û—Ç–∫–ª–æ–Ω–µ–Ω–æ: –Ω–µ—Ç title (id={post_id})")
                continue

            if not post.get("description"):
                rejection_reasons[post_id] = "missing_description"
                logger.debug(f"–û—Ç–∫–ª–æ–Ω–µ–Ω–æ: –Ω–µ—Ç description (id={post_id})")
                continue

            if not post.get("text"):
                rejection_reasons[post_id] = "missing_text"
                logger.debug(f"–û—Ç–∫–ª–æ–Ω–µ–Ω–æ: –Ω–µ—Ç text –¥–ª—è embeddings (id={post_id})")
                continue

            valid_posts.append(post)

        if not valid_posts:
            logger.warning("AutoModerator: –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω—ã –Ω–∞ —ç—Ç–∞–ø–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
            return ModerationResult(
                approved_posts=[],
                rejected_posts=posts,
                rejection_reasons=rejection_reasons,
            )

        logger.info(f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è: {len(valid_posts)}/{len(posts)} –ø—Ä–æ—à–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫—É –ø–æ–ª–µ–π")

        # –®–ê–ì 2: –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ score (–æ—Ç –±–æ–ª—å—à–µ–≥–æ –∫ –º–µ–Ω—å—à–µ–º—É)
        valid_posts.sort(key=lambda x: x.get("score", 0), reverse=True)

        # –®–ê–ì 3: –§–∏–Ω–∞–ª—å–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
        unique_posts, duplicates = await self._deduplicate(valid_posts)

        for dup in duplicates:
            post_id = dup.get("source_message_id", id(dup))
            rejection_reasons[post_id] = "duplicate_in_final"

        logger.info(f"‚úÖ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è: {len(unique_posts)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö, {len(duplicates)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")

        # –®–ê–ì 4: –û—Ç–±–æ—Ä —Ç–æ–ø-N
        approved = unique_posts[:target_count]
        rejected_by_limit = unique_posts[target_count:]

        for post in rejected_by_limit:
            post_id = post.get("source_message_id", id(post))
            rejection_reasons[post_id] = "exceeded_top_n_limit"

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—Ç–∫–ª–æ–Ω—ë–Ω–Ω—ã–µ
        all_rejected = [p for p in posts if p not in approved]

        logger.info(
            f"üéØ AutoModerator –∑–∞–≤–µ—Ä—à—ë–Ω: {len(approved)} –æ–¥–æ–±—Ä–µ–Ω–æ, "
            f"{len(all_rejected)} –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ"
        )

        # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
        for idx, post in enumerate(approved, 1):
            logger.debug(
                f"  {idx}. [{post.get('score', 0)}/10] {post.get('title', '')[:50]}..."
            )

        return ModerationResult(
            approved_posts=approved,
            rejected_posts=all_rejected,
            rejection_reasons=rejection_reasons,
        )

    async def _deduplicate(
        self,
        posts: list[dict],
    ) -> tuple[list[dict], list[dict]]:
        """
        –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ embeddings.

        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞–∂–¥—É—é –Ω–æ–≤–æ—Å—Ç—å –Ω–∞ —Å—Ö–æ–∂–µ—Å—Ç—å —Å —É–∂–µ –ø—Ä–∏–Ω—è—Ç—ã–º–∏.

        Args:
            posts: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π (—É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ score)

        Returns:
            Tuple (unique_posts, duplicates)
        """
        if not posts:
            return [], []

        unique: list[dict] = []
        duplicates: list[dict] = []
        seen_embeddings: list[np.ndarray] = []

        # –°–æ–∑–¥–∞—ë–º embeddings –¥–ª—è –≤—Å–µ—Ö –ø–æ—Å—Ç–æ–≤ –∑–∞ –æ–¥–∏–Ω batch-–≤—ã–∑–æ–≤
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π text –¥–ª—è —Ç–æ—á–Ω–æ–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (LLM-–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ title/description –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è)
        texts = [
            post.get('text', f"{post.get('title', '')} {post.get('description', '')}")
            for post in posts
        ]

        embeddings_array = await self.embeddings.encode_batch_async(texts, batch_size=32)

        for post, embedding in zip(posts, embeddings_array):
            if not seen_embeddings:
                # –ü–µ—Ä–≤—ã–π –ø–æ—Å—Ç –≤—Å–µ–≥–¥–∞ —É–Ω–∏–∫–∞–ª–µ–Ω
                unique.append(post)
                seen_embeddings.append(embedding)
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º similarity —Å —É–∂–µ –ø—Ä–∏–Ω—è—Ç—ã–º–∏
            seen_matrix = np.array(seen_embeddings)
            similarities = self.embeddings.batch_cosine_similarity(embedding, seen_matrix)
            max_similarity = np.max(similarities) if len(similarities) > 0 else 0.0

            if max_similarity >= self.duplicate_threshold:
                # –ù–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç
                duplicates.append(post)
                duplicate_idx = int(np.argmax(similarities))
                logger.debug(
                    f"üîç –î—É–±–ª–∏–∫–∞—Ç: '{post.get('title', '')[:40]}...' "
                    f"–ø–æ—Ö–æ–∂–∞ –Ω–∞ #{duplicate_idx + 1} (sim={max_similarity:.3f})"
                )
            else:
                # –£–Ω–∏–∫–∞–ª—å–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å
                unique.append(post)
                seen_embeddings.append(embedding)

        return unique, duplicates

    @staticmethod
    def ensure_post_fields(post: dict) -> dict:
        """
        –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π –≤ –ø–æ—Å—Ç–µ.

        –ï—Å–ª–∏ title –∏–ª–∏ description –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç, –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–∑ text.

        Args:
            post: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ—Å—Ç–∞

        Returns:
            –ü–æ—Å—Ç —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏ title, description
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º title
        if not post.get("title"):
            text = post.get("text", "")
            if text:
                lines = text.split("\n", 1)
                first_line = lines[0].strip()
                words = first_line.split()
                post["title"] = " ".join(words[:7]) if len(words) > 7 else first_line
            else:
                post["title"] = "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º description
        if not post.get("description"):
            text = post.get("text", "")
            if text:
                lines = text.split("\n", 1)
                if len(lines) > 1:
                    post["description"] = lines[1].strip()[:200]
                else:
                    words = text.split()
                    post["description"] = " ".join(words[7:])[:200] if len(words) > 7 else text[:200]
            else:
                post["description"] = "–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"

        return post
